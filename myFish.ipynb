{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Perform initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda\n",
    "%matplotlib inline\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function\n",
    "path = \"\"\n",
    "batch_size = 64\n",
    "validation_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a 20% validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preserve the class imbalances in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/train\n",
      "/home/ubuntu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'/home/ubuntu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd \"train\"\n",
    "species = glob(\"*\")\n",
    "for d in species:\n",
    "    os.mkdir('../valid/'+d)\n",
    "    images = glob(d+\"/*\")\n",
    "    shuf = np.random.permutation(images)\n",
    "    sample_size = int(round(len(images) * validation_size , 0))\n",
    "    for i in range(sample_size): os.rename(shuf[i], '../valid/' + shuf[i])\n",
    "%cd ..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3022 images belonging to 8 classes.\n",
      "Found 755 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels , trn_labels, val_filenames, trn_filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_filenames = [f.split('/')[-1] for f in trn_filenames]\n",
    "raw_test_filenames = [f.split('/')[-1] for f in test_filenames]\n",
    "raw_val_filenames = [f.split('/')[-1] for f in val_filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg640 = Vgg16BN((360,640)).model\n",
    "vgg640.pop()\n",
    "#vgg640.input_shape()\n",
    "#vgg640.output_shape()\n",
    "vgg640.compile(Adam(), 'categorical_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data in 360 X 640 format and augment it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduce random variations in the training data including rotation, width shift, zoom etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, \n",
    "                               shear_range=0.15, zoom_range = 0.1 , channel_shift_range = 10. , horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3022 images belonging to 8 classes.\n",
      "Found 755 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path+'train', gen,shuffle=False, batch_size=1, class_mode=None, target_size=(360,640))\n",
    "trn = np.concatenate([batches.next() for i in range(batches.nb_sample)])\n",
    "\n",
    "batches = get_batches(path+'valid', shuffle=False, batch_size=1, class_mode=None, target_size=(360,640))\n",
    "val = np.concatenate([batches.next() for i in range(batches.nb_sample)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3022/3022 [==============================] - 383s   \n",
      "755/755 [==============================] - 95s    \n"
     ]
    }
   ],
   "source": [
    "trn_features = vgg640.predict(trn, batch_size = 32, verbose =1)\n",
    "val_features = vgg640.predict(val, batch_size = 32, verbose =1)\n",
    "del trn, val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 1 classes.\n",
      "1000/1000 [==============================] - 126s   \n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path+'test', shuffle=False, batch_size=1, class_mode=None, target_size=(360,640))\n",
    "test = np.concatenate([batches.next() for i in range(batches.nb_sample)])\n",
    "test_features = vgg640.predict(test, batch_size = 32, verbose =1)\n",
    "del test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a copy or load it from disk, if available \n",
    "\n",
    "################################################    RESUME FROM HERE   ###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FIRST_TIME = True\n",
    "if(FIRST_TIME):\n",
    "    save_array(path+'val_features.dat', val_features)\n",
    "    save_array(path+'trn_features.dat', trn_features)\n",
    "    save_array(path+'test_features.dat', test_features)\n",
    "else:\n",
    "    val_features = load_array(path+'val_features.dat')\n",
    "    trn_features = load_array(path+'trn_features.dat')\n",
    "    test_features = load_array(path+'test_features.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the final dense layer making this is a fully convolutional net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_layers,_ = split_at(vgg640,Convolution2D)\n",
    "nf=128\n",
    "p = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add four convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "batchnormalization_13 (BatchNorma(None, 512, 22, 40)   1024        batchnormalization_input_4[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_26 (Convolution2D) (None, 128, 22, 40)   589952      batchnormalization_13[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_14 (BatchNorma(None, 128, 22, 40)   256         convolution2d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_15 (MaxPooling2D)   (None, 128, 11, 20)   0           batchnormalization_14[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_27 (Convolution2D) (None, 128, 11, 20)   147584      maxpooling2d_15[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_15 (BatchNorma(None, 128, 11, 20)   256         convolution2d_27[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_16 (MaxPooling2D)   (None, 128, 5, 10)    0           batchnormalization_15[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_28 (Convolution2D) (None, 128, 5, 10)    147584      maxpooling2d_16[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_16 (BatchNorma(None, 128, 5, 10)    256         convolution2d_28[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_17 (MaxPooling2D)   (None, 128, 5, 5)     0           batchnormalization_16[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_29 (Convolution2D) (None, 8, 5, 5)       9224        maxpooling2d_17[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 8, 5, 5)       0           convolution2d_29[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "globalaveragepooling2d_4 (GlobalA(None, 8)             0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 8)             0           globalaveragepooling2d_4[0][0]   \n",
      "====================================================================================================\n",
      "Total params: 896136\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_final_layers():\n",
    "    return [\n",
    "        BatchNormalization(axis=1, input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((1,2)),\n",
    "        Convolution2D(8,3,3, border_mode='same'),\n",
    "        Dropout(p),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Activation('softmax')\n",
    "    ]\n",
    "myModel = Sequential(get_final_layers())\n",
    "myModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a couple of epochs with high learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3022 samples, validate on 755 samples\n",
      "Epoch 1/3\n",
      "3022/3022 [==============================] - 14s - loss: 1.0322 - acc: 0.6400 - val_loss: 2.5454 - val_acc: 0.5960\n",
      "Epoch 2/3\n",
      "3022/3022 [==============================] - 14s - loss: 0.3038 - acc: 0.9120 - val_loss: 1.2869 - val_acc: 0.6543\n",
      "Epoch 3/3\n",
      "3022/3022 [==============================] - 14s - loss: 0.1247 - acc: 0.9619 - val_loss: 0.5624 - val_acc: 0.8305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40aedde950>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myModel.compile(Adam(lr=0.001),loss='categorical_crossentropy' , metrics = ['accuracy'])\n",
    "myModel.fit(trn_features, trn_labels, batch_size = batch_size, nb_epoch = 3 , validation_data = (val_features, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train another 6 epochs with low learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3022 samples, validate on 755 samples\n",
      "Epoch 1/6\n",
      "3022/3022 [==============================] - 14s - loss: 0.0690 - acc: 0.9831 - val_loss: 0.4402 - val_acc: 0.8543\n",
      "Epoch 2/6\n",
      "3022/3022 [==============================] - 14s - loss: 0.0475 - acc: 0.9844 - val_loss: 0.4231 - val_acc: 0.9099\n",
      "Epoch 3/6\n",
      "3022/3022 [==============================] - 14s - loss: 0.0693 - acc: 0.9815 - val_loss: 0.6725 - val_acc: 0.8477\n",
      "Epoch 4/6\n",
      "3022/3022 [==============================] - 14s - loss: 0.0535 - acc: 0.9851 - val_loss: 0.6150 - val_acc: 0.8384\n",
      "Epoch 5/6\n",
      "3022/3022 [==============================] - 14s - loss: 0.0279 - acc: 0.9921 - val_loss: 0.4554 - val_acc: 0.8954\n",
      "Epoch 6/6\n",
      "3022/3022 [==============================] - 14s - loss: 0.0072 - acc: 0.9990 - val_loss: 0.3988 - val_acc: 0.9139\n",
      "755/755 [==============================] - 1s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39876778318195155, 0.91390728532083776]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myModel.optimizer.lr=1e-4\n",
    "myModel.fit(trn_features, trn_labels, batch_size = batch_size, nb_epoch = 6 , validation_data = (val_features, val_labels))\n",
    "myModel.save_weights(path+'myModel.h5')\n",
    "myModel.evaluate(val_features,val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_clip(arr, mx): return np.clip(arr, (1-mx)/7, mx)\n",
    "predictions = myModel.predict(test_features, batch_size = batch_size)\n",
    "predictions_clipped = do_clip(predictions, 0.72)\n",
    "classes = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "submission = pd.DataFrame(predictions_clipped, columns=classes)\n",
    "submission.insert(0, 'image', raw_test_filenames)\n",
    "submission.head()\n",
    "subm_name = path+'submission.csv'\n",
    "submission.to_csv(subm_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
