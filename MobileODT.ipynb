{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Be Done:\n",
    "\n",
    "Add code to handle IO Exceptions due to bad image files\n",
    "\n",
    "Change hardcoded paths to use one parameter variable\n",
    "\n",
    "Add code to create file structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle : 2 Sigma Connect : Rental Listing Inquiries\n",
    "\n",
    "Purpose: To predict the interest level of a listing using the listing \n",
    "images only\n",
    "\n",
    "Author : Chandan Panda \n",
    "\n",
    "Version: 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available  (error: Unable to get the number of gpus available: unknown error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cp/home/ubuntu/intel\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from random import uniform\n",
    "import bcolz\n",
    "import time\n",
    "from keras.layers import merge\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers import Input, Dense\n",
    "import math\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils as u\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "import gc\n",
    "\n",
    "%matplotlib inline\n",
    "%cd '/cp/home/ubuntu/intel'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly divide the dataset into 5 folds and also keep a small sample dataset for debugging. Each fold contains about 54000 images\n",
    "\n",
    "The images are structured into folders named high, medium or low based on the interest level of the listing in which the image was uploaded\n",
    "\n",
    "We make sure that a listing's images are not scattered across both different folds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create 5 fold datasets\n",
    "\n",
    "def setupFiles(path,NumberOfFolds,folder):\n",
    "    os.chdir(path)\n",
    "    photos=glob(\"*.jpg\")\n",
    "\n",
    "    CREATE_FOLDS = True\n",
    "\n",
    "    if CREATE_FOLDS==True:\n",
    "        photos=glob(\"*.jpg\")\n",
    "        shuffled_photos = np.random.permutation(photos)\n",
    "        sample_size = int(round(len(photos) * (1/NumberOfFolds),0))\n",
    "\n",
    "        for i in range(int(NumberOfFolds)):\n",
    "            if(os.path.exists('/cp/home/ubuntu/intel/folds/fold_'+str(i))==False):\n",
    "                os.mkdir('/cp/home/ubuntu/intel/folds/fold_'+str(i))\n",
    "            if(os.path.exists('/cp/home/ubuntu/intel/folds/fold_'+str(i)+'/' + folder)==False):\n",
    "                os.mkdir('/cp/home/ubuntu/intel/folds/fold_'+str(i)+'/' + folder)\n",
    "            for photo in shuffled_photos[range(i*sample_size,min(((i*sample_size)+sample_size),len(shuffled_photos) )) ]:\n",
    "                os.rename(photo, '/cp/home/ubuntu/intel/folds/'+'fold_'+str(i)+'/' + folder + '/'+ photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setupFiles('/cp/home/ubuntu/intel/all/Type_1',5.0,'Type_1')\n",
    "setupFiles('/cp/home/ubuntu/intel/all/Type_2',5.0,'Type_2')\n",
    "setupFiles('/cp/home/ubuntu/intel/all/Type_3',5.0,'Type_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample a few images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Pre-trained Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a version of the VGG network (a convolutional neural network by the Visual Geometry and Graphics group) that is trained of the ImageNet database to predict 1000 classes\n",
    "\n",
    "This version includes batch normalization layers that ensure that the weights not not become too large and improves the training time. In addition, it normalizes the image by subtracting the RGB mean values from the ImageNet database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://files.fast.ai/models/vgg16_bn.h5\n",
      "553566208/553620808 [============================>.] - ETA: 0sDownloading data from http://files.fast.ai/models/imagenet_class_index.json\n",
      "40960/35363 [==================================] - 0s \n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 3, 224, 224)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 224, 224)  0           zeropadding2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)  (None, 64, 226, 226)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 224, 224)  0           zeropadding2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 112, 112)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_3 (ZeroPadding2D)  (None, 64, 114, 114)  0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 112, 112) 0           zeropadding2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_4 (ZeroPadding2D)  (None, 128, 114, 114) 0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 128, 112, 112) 0           zeropadding2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 56, 56)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 128, 58, 58)   0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 256, 56, 56)   0           zeropadding2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_6 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 256, 56, 56)   0           zeropadding2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_7 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 256, 56, 56)   0           zeropadding2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 28, 28)   0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_8 (ZeroPadding2D)  (None, 256, 30, 30)   0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 512, 28, 28)   0           zeropadding2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_9 (ZeroPadding2D)  (None, 512, 30, 30)   0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 512, 28, 28)   0           zeropadding2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_10 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 512, 28, 28)   0           zeropadding2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 512, 14, 14)   0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_11 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 512, 14, 14)   0           zeropadding2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_12 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 512, 14, 14)   0           zeropadding2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_13 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 512, 14, 14)   0           zeropadding2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 512, 7, 7)     0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 25088)         0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4096)          0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNormal(None, 4096)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4096)          0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 4096)          0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNormal(None, 4096)          0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4096)          0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 3)             12291       dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 12291\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from vgg16bn import Vgg16BN\n",
    "model = vgg_ft_bn(3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split the VGG network into the convolutional and dense layers. This is so that we can reuse the convolutional layers weights as it is and train only the final three dense layers. This will save enormous amount of time while making little difference to our final performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "gen=image.ImageDataGenerator(width_shift_range = 0.2 , height_shift_range = 0.2 , shear_range = 0.2 , zoom_range = 0.2)\n",
    "target_size=(224,224)\n",
    "batch_size = 64\n",
    "class_mode='categorical'\n",
    "shuffle=True\n",
    "dirname = 'train'\n",
    "model.compile(optimizer=Adam(1e-3),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "conv_layers,fc_layers = split_at(model, Convolution2D)\n",
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess all images in sample, training and validation sets by passing through the VGG network convolutional layers after a bit of data augmentation. These features (i.e. 512 X 14 X 14 per image) will then be used as inputs  to a dense layer network that finally outputs the probability of the image being low, medium or high interest_level\n",
    "\n",
    "Because of the large number of images (~200k training set, ~70k in validation set) and RAM constraint of 64 GB, we will divide the features into chunks of 10k images and use the fit_generator and evaluate_generator to iterate through each file chunk as we train and validate the dense layer network.\n",
    "\n",
    "Also, the images are randomly width shifted, height shifted, sheared and zoomed to introduce bias in order to reduce variance\n",
    "\n",
    "Each epoch will take approximately an hour!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateFeatures(dirname,CHUNK_SIZE = 10000):\n",
    "    GENERATE_FEATURES = True\n",
    "    if GENERATE_FEATURES==True:\n",
    "        batches = gen.flow_from_directory('/cp/home/ubuntu/intel/folds/'+dirname, \n",
    "                                                         target_size=target_size,class_mode=class_mode, \n",
    "                                          shuffle=True, batch_size=1)\n",
    "        labels_all = onehot(batches.classes) \n",
    "        totalImages = batches.nb_sample\n",
    "        listing_ids_all = np.ndarray([totalImages,1],dtype=np.int64)\n",
    "        listing_ids_all = [int((f.split('.')[0].split('/')[1])) for f in batches.filenames]\n",
    "        batchIndex = 0\n",
    "        numImages = 0\n",
    "        images = np.ndarray([CHUNK_SIZE,3, 224, 224],dtype=np.float32)\n",
    "        labels = np.ndarray([CHUNK_SIZE,3],dtype=np.float64)\n",
    "        listing_ids = np.ndarray([CHUNK_SIZE,1],dtype=np.int64)   \n",
    "        for i in range(totalImages):\n",
    "            if (numImages > (CHUNK_SIZE - 1)) or (i == (totalImages-1)):\n",
    "                labels = labels_all[batchIndex*CHUNK_SIZE:batchIndex*CHUNK_SIZE + numImages]\n",
    "                listing_ids = listing_ids_all[batchIndex*CHUNK_SIZE:batchIndex*CHUNK_SIZE + numImages]\n",
    "                save_array('features/' + dirname + '_labels_%d.dat'%batchIndex,labels[0:numImages])               \n",
    "                save_array('features/' + dirname + '_listing_ids_%d.dat'%batchIndex,listing_ids[0:numImages])                     \n",
    "                conv_feat = conv_model.predict_generator(generator=gen.flow(images[0:numImages],batch_size=batch_size)\n",
    "                                                         ,val_samples=numImages)        \n",
    "                save_array('features/' + dirname + '_trainX_%d.dat'%batchIndex,conv_feat[0:numImages])  \n",
    "                batchIndex += 1\n",
    "                images = np.ndarray([CHUNK_SIZE,3, 224, 224],dtype=np.float32)\n",
    "                labels = np.ndarray([CHUNK_SIZE,3],dtype=np.float64)\n",
    "                numImages = 0\n",
    "                del(conv_feat)\n",
    "                del(labels)\n",
    "                gc.collect()            \n",
    "            x,y = batches.next()\n",
    "            images[numImages] = x[0]\n",
    "            numImages += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1736 images belonging to 3 classes.\n",
      "Found 1738 images belonging to 3 classes.\n",
      "Found 675 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "generateFeatures('fold_0',CHUNK_SIZE=20000)\n",
    "generateFeatures('fold_1',CHUNK_SIZE=20000)\n",
    "generateFeatures('fold_2',CHUNK_SIZE=20000)\n",
    "generateFeatures('fold_3',CHUNK_SIZE=20000)\n",
    "generateFeatures('fold_4',CHUNK_SIZE=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bad Image Files 5892,2845,5893"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move augmented features to another folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cp/home/ubuntu/intel/features\n",
      "/cp/home/ubuntu/intel\n"
     ]
    }
   ],
   "source": [
    "%cd '/cp/home/ubuntu/intel/features'\n",
    "photos=glob(\"*fold*.dat\")\n",
    "for photo in photos:\n",
    "    os.rename(photo, '/cp/home/ubuntu/intel/features-aug/'+photo)\n",
    "%cd '/cp/home/ubuntu/intel'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to randomize fold feature chunks. This is currently hardcoded to handle exactly 1 filechunk per fold!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomizeFeatures(fold,folder):\n",
    "    os.chdir(folder)\n",
    "    Files = glob(fold+'_trainX*.dat')\n",
    "    chunk0 = load_array(Files[0])\n",
    "    chunk0size = chunk0.shape[0]\n",
    "    labels_chunk0 = load_array(Files[0].replace('trainX','labels'))\n",
    "    listing_ids_chunk0 = load_array(Files[0].replace('trainX','listing_ids'))\n",
    "    features = chunk0\n",
    "    del(chunk0)\n",
    "    gc.collect()\n",
    "    labels = labels_chunk0\n",
    "    del(labels_chunk0)\n",
    "    gc.collect()\n",
    "    listing_ids = listing_ids_chunk0\n",
    "    del(listing_ids_chunk0)\n",
    "    gc.collect()\n",
    "\n",
    "    seq = np.random.permutation(range(features.shape[0]))\n",
    "\n",
    "    tempArrayFeatures = np.ndarray([1,512, 14, 14],dtype=np.float32)\n",
    "    tempArrayListingIds = 0\n",
    "    tempArrayLabels = np.ndarray([1,3],dtype=np.float32)\n",
    "\n",
    "    for i in range(features.shape[0]):\n",
    "        tempArrayFeatures[0] = features[seq[i]]\n",
    "        features[seq[i]] = features[i]\n",
    "        features[i] = tempArrayFeatures[0]\n",
    "        tempArrayListingIds = listing_ids[seq[i]]\n",
    "        listing_ids[seq[i]] = listing_ids[i]\n",
    "        listing_ids[i] = tempArrayListingIds\n",
    "        tempArrayLabels[0] = labels[seq[i]]\n",
    "        labels[seq[i]] = labels[i]\n",
    "        labels[i] = tempArrayLabels[0]\n",
    "\n",
    "    save_array(Files[0],features[range(chunk0size)])\n",
    "    save_array(Files[0].replace('trainX','labels'),labels[range(chunk0size)])\n",
    "    save_array(Files[0].replace('trainX','listing_ids'),listing_ids[range(chunk0size)])\n",
    "    os.chdir('/cp/home/ubuntu/intel')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkLabels(folder):    \n",
    "    os.chdir(folder)\n",
    "    chunks=glob(\"fold_*_labels_*.dat\")\n",
    "    gc.collect()\n",
    "    for chunk in chunks:\n",
    "        labels = load_array(chunk)\n",
    "        print(chunk,np.sum(labels[:,0]),np.sum(labels[:,1]),np.sum(labels[:,2]))\n",
    "    os.chdir('/cp/home/ubuntu/intel')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fold_0_labels_0.dat', 335.0, 938.0, 464.0)\n",
      "('fold_2_labels_0.dat', 335.0, 936.0, 464.0)\n",
      "('fold_3_labels_0.dat', 335.0, 938.0, 464.0)\n",
      "('fold_1_labels_0.dat', 334.0, 938.0, 464.0)\n",
      "('fold_4_labels_0.dat', 54.0, 156.0, 464.0)\n"
     ]
    }
   ],
   "source": [
    "checkLabels('/cp/home/ubuntu/intel/features-aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "randomizeFeatures('fold_0','/cp/home/ubuntu/intel/features-aug')\n",
    "randomizeFeatures('fold_1','/cp/home/ubuntu/intel/features-aug')\n",
    "randomizeFeatures('fold_2','/cp/home/ubuntu/intel/features-aug')\n",
    "randomizeFeatures('fold_3','/cp/home/ubuntu/intel/features-aug')\n",
    "randomizeFeatures('fold_4','/cp/home/ubuntu/intel/features-aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fold_0_labels_0.dat', 335.0, 938.0, 464.0)\n",
      "('fold_2_labels_0.dat', 335.0, 936.0, 464.0)\n",
      "('fold_3_labels_0.dat', 335.0, 938.0, 464.0)\n",
      "('fold_1_labels_0.dat', 334.0, 938.0, 464.0)\n",
      "('fold_4_labels_0.dat', 54.0, 156.0, 464.0)\n"
     ]
    }
   ],
   "source": [
    "checkLabels('/cp/home/ubuntu/intel/features-aug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dense layer network with batch normalization to reduce the time it takes to train. Also include a drop out of 0.4 to improve the validation accuracy. This network takes the pre-processed features from the saved numpy arrays and outputs 3 probabilities - interest level will be low, medium or high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        BatchNormalization(axis=1),\n",
    "        Dropout(p/4),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(3, activation='softmax')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a network on such a large dataset requires us to use the generator functions in keras. These functions loop \n",
    "indefinitely and return to the yield statement the next time the function is called. This allows us to iterate through the \n",
    "image features one batch at a time till all of them are passed through the network. Once a numpy array is completed, the next \n",
    "one is loaded from memory so that at any given time, a maximum of 20k images are in memory.\n",
    "\n",
    "The metrics such as validation categorical cross-entropy loss and accuracy are logged to a log file so that even if \n",
    "we lose the connection midway, we can review how the metrics changed across the epochs\n",
    "\n",
    "Finally, we keep saving the best model's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainMyNw(nb_epoch,fold,folder):\n",
    "    \n",
    "    myGen=image.ImageDataGenerator()\n",
    "    best_loss_metric = 999\n",
    "\n",
    "    for e in tqdm(range(nb_epoch)):\n",
    "        \n",
    "        start = time.clock()\n",
    "        f = open('/cp/home/ubuntu/intel/results/log.txt', 'a')       \n",
    "        featureFiles = glob(folder + '/' + 'fold_*_trainX_*.dat')        \n",
    "        chunkCount=0\n",
    "        \n",
    "        for files in featureFiles:\n",
    "            if files.find(fold) == -1:\n",
    "                features = load_array(files)\n",
    "                labels = load_array(files.replace('trainX','labels'))\n",
    "                chunkCount += 1\n",
    "                numImages = features.shape[0]\n",
    "                bn_model.fit_generator(generator=myGen.flow(features,labels),samples_per_epoch = numImages,nb_epoch=1,verbose=0)  \n",
    "                del(features)\n",
    "                del(labels)\n",
    "                gc.collect()\n",
    "            \n",
    "        featureFiles = glob(folder + '/' + fold + '_trainX_*.dat')        \n",
    "        accuracy = 0\n",
    "        loss = 0\n",
    "        avg_accuracy = 0\n",
    "        avg_loss = 0\n",
    "        chunkCount = 0\n",
    "        totalImages = 0\n",
    "\n",
    "        for files in featureFiles:\n",
    "            features = load_array(files)\n",
    "            labels = load_array(files.replace('trainX','labels'))\n",
    "            chunkCount += 1\n",
    "            numImages = features.shape[0]\n",
    "            loss_metrics = bn_model.evaluate_generator(generator=myGen.flow(features,labels),\n",
    "                                                       val_samples = numImages) \n",
    "            accuracy += (loss_metrics[1]*numImages)\n",
    "            loss += (loss_metrics[0]*numImages)\n",
    "            totalImages += numImages\n",
    "            del(features)\n",
    "            del(labels) \n",
    "            gc.collect()            \n",
    "            \n",
    "        if chunkCount>0: \n",
    "            avg_accuracy = accuracy/totalImages\n",
    "            avg_loss = loss/totalImages\n",
    "            \n",
    "        print bn_model.metrics_names,avg_loss,avg_accuracy, \"time :\", time.clock() - start\n",
    "        f.write(str(bn_model.metrics_names))\n",
    "        f.write(\" : \")\n",
    "        f.write(str(avg_loss))\n",
    "        f.write(\" : \")\n",
    "        f.write(str(avg_accuracy))\n",
    "        f.write(\" : time :\")\n",
    "        f.write(str(time.clock() - start))\n",
    "        f.write(\"\\n\")        \n",
    "        f.close() \n",
    "        if (avg_loss<best_loss_metric):\n",
    "            bn_model.save_weights('/cp/home/ubuntu/intel/results/best.hdf5') \n",
    "            best_loss_metric = avg_loss\n",
    "            \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the network with a high learning rate once and then gradually decrease the learning rate as we go through about 12 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dropout of 0.2 is optimal for training on train dataset while a dropout of 0.4 suits the valid dataset. Train the network twice, once on the training and once on the validation dataset and save the versions with the lowest loss for later use for stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save best model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p=0.9\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "trainMyNw(1,'fold_0','features-aug')\n",
    "bn_model.optimizer.lr=0.001\n",
    "trainMyNw(1,'fold_0','features-aug')\n",
    "os.rename('/cp/home/ubuntu/intel/results/best.hdf5', '/cp/home/ubuntu/data/results/fold_0_XXXXn.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.9\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "trainMyNw(1,'fold_1','features-aug')\n",
    "bn_model.optimizer.lr=0.001\n",
    "trainMyNw(1,'fold_1','features-aug')\n",
    "os.rename('/cp/home/ubuntu/intel/results/best.hdf5', '/cp/home/ubuntu/data/results/fold_1_XXXXn.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.9\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "trainMyNw(1,'fold_2','features-aug')\n",
    "bn_model.optimizer.lr=0.001\n",
    "trainMyNw(1,'fold_2','features-aug')\n",
    "os.rename('/cp/home/ubuntu/intel/results/best.hdf5', '/cp/home/ubuntu/data/results/fold_2_XXXXn.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.9\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "trainMyNw(1,'fold_3','features-aug')\n",
    "bn_model.optimizer.lr=0.001\n",
    "trainMyNw(1,'fold_3','features-aug')\n",
    "os.rename('/cp/home/ubuntu/intel/results/best.hdf5', '/cp/home/ubuntu/data/results/fold_3_XXXXn.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.9\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "trainMyNw(1,'fold_4','features-aug')\n",
    "bn_model.optimizer.lr=0.001\n",
    "trainMyNw(1,'fold_4','features-aug')\n",
    "os.rename('/cp/home/ubuntu/intel/results/best.hdf5', '/cp/home/ubuntu/data/results/fold_4_XXXXn.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train final model on entire dataset. Manually set the number of epochs based on analysis of training logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p=0.9\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "trainMyNw(1,'sample','features-aug')\n",
    "bn_model.optimizer.lr=0.001\n",
    "trainMyNw(1,'sample','features-aug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights('/cp/home/ubuntu/data/results/fold_all_XXXXn.hdf5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a folder with photos for entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate features for final scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate features for Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen=image.ImageDataGenerator()\n",
    "generateFeatures('test',CHUNK_SIZE=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate features for all folds without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen=image.ImageDataGenerator()\n",
    "generateFeatures('fold_0',CHUNK_SIZE=20000)\n",
    "generateFeatures('fold_1',CHUNK_SIZE=20000)\n",
    "generateFeatures('fold_2',CHUNK_SIZE=20000)\n",
    "generateFeatures('fold_3',CHUNK_SIZE=20000)\n",
    "generateFeatures('fold_4',CHUNK_SIZE=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randomizeFeatures('fold_0','/cp/home/ubuntu/intel/features')\n",
    "randomizeFeatures('fold_1','/cp/home/ubuntu/intel/features')\n",
    "randomizeFeatures('fold_2','/cp/home/ubuntu/intel/features')\n",
    "randomizeFeatures('fold_3','/cp/home/ubuntu/intel/features')\n",
    "randomizeFeatures('fold_4','/cp/home/ubuntu/intel/features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkLabels('/cp/home/ubuntu/intel/features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scoreMyData(fold,weights_path):\n",
    "    gen=image.ImageDataGenerator()\n",
    "    bn_model.load_weights(weights_path) \n",
    "    featureFiles = glob('features/' + fold + '_trainX_*.dat')        \n",
    "\n",
    "    for files in featureFiles:\n",
    "        features = load_array(files)\n",
    "        numImages = features.shape[0]\n",
    "        scores = np.ndarray([numImages,3],dtype=np.float64)\n",
    "        scores = bn_model.predict_generator(generator=gen.flow(features),val_samples = numImages)       \n",
    "        save_array('predictions/' + files.split('/')[1].replace('trainX','scores'),scores)               \n",
    "        del(scores)\n",
    "        del(features)\n",
    "        gc.collect()            \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scoreMyData('sample','/cp/home/ubuntu/intel/results/fold_0_XXXXn.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Score all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scoreMyData('fold_0','/cp/home/ubuntu/intel/results/fold_0_XXXXn.hdf5')\n",
    "scoreMyData('fold_1','/cp/home/ubuntu/intel/results/fold_1_XXXXn.hdf5')\n",
    "scoreMyData('fold_2','/cp/home/ubuntu/intel/results/fold_2_XXXXn.hdf5')\n",
    "scoreMyData('fold_3','/cp/home/ubuntu/intel/results/fold_3_XXXXn.hdf5')\n",
    "scoreMyData('fold_4','/cp/home/ubuntu/intel/results/fold_4_XXXXn.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Score test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scoreMyData('test','/cp/home/ubuntu/intel/results/fold_all_XXXXn.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create final Predictions file extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd '/cp/home/ubuntu/intel/predictions'\n",
    "scoreFiles = glob('*scores*.dat') \n",
    "listing_ids_all = load_array('/cp/home/ubuntu/intel/features/' + scoreFiles[0].replace('scores','listing_ids'))\n",
    "scores_all = load_array(scoreFiles[0])\n",
    "\n",
    "for i in range(2,len(scoreFiles)):\n",
    "    files =  scoreFiles[i]\n",
    "    listing_ids = load_array('/cp/home/ubuntu/intel/features/' + files.replace('scores','listing_ids'))\n",
    "    scores = load_array(files)\n",
    "    listing_ids_all = np.concatenate((listing_ids_all, listing_ids))\n",
    "    scores_all = np.vstack((scores_all, scores))\n",
    "\n",
    "listing_ids_all.shape,scores_all.shape  \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame(listing_ids_all)\n",
    "df.to_csv(\"listing_ids_all.csv\")\n",
    "\n",
    "df = pd.DataFrame(scores_all)\n",
    "df.to_csv(\"scores_all.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's all Folks !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features1 = load_array('/cp/home/ubuntu/intel/features-aug/fold_2_trainX_0.dat')\n",
    "labels1 = load_array('/cp/home/ubuntu/intel/features-aug/fold_2_labels_0.dat')\n",
    "features2 = load_array('/cp/home/ubuntu/intel/features-aug/fold_3_trainX_0.dat')\n",
    "labels2 = load_array('/cp/home/ubuntu/intel/features-aug/fold_3_labels_0.dat')\n",
    "features3 = load_array('/cp/home/ubuntu/intel/features-aug/fold_1_trainX_0.dat')\n",
    "labels3 = load_array('/cp/home/ubuntu/intel/features-aug/fold_1_labels_0.dat')\n",
    "\n",
    "features = np.vstack((features1,features2,features3))\n",
    "labels = np.vstack((labels1,labels2,labels3))\n",
    "\n",
    "del(features1)\n",
    "del(features2)\n",
    "del(labels1)\n",
    "del(labels2)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features1 = load_array('/cp/home/ubuntu/intel/features-aug/fold_0_trainX_0.dat')\n",
    "labels1 = load_array('/cp/home/ubuntu/intel/features-aug/fold_0_labels_0.dat')\n",
    "features2 = load_array('/cp/home/ubuntu/intel/features-aug/fold_4_trainX_0.dat')\n",
    "labels2 = load_array('/cp/home/ubuntu/intel/features-aug/fold_4_labels_0.dat')\n",
    "\n",
    "features_val = np.vstack((features1,features2))\n",
    "labels_val = np.vstack((labels1,labels2))\n",
    "\n",
    "del(features1)\n",
    "del(features2)\n",
    "del(labels1)\n",
    "del(labels2)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5208, 512, 14, 14), (2411, 512, 14, 14), (5208, 3), (2411, 3))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape,features_val.shape,labels.shape,labels_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.8\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5208 samples, validate on 2411 samples\n",
      "Epoch 1/2\n",
      "5208/5208 [==============================] - 3s - loss: 1.5765 - acc: 0.4180 - val_loss: 2.3474 - val_acc: 0.3625\n",
      "Epoch 2/2\n",
      "5208/5208 [==============================] - 3s - loss: 1.2145 - acc: 0.4618 - val_loss: 1.4567 - val_acc: 0.4467\n",
      "Train on 5208 samples, validate on 2411 samples\n",
      "Epoch 1/2\n",
      "5208/5208 [==============================] - 3s - loss: 1.1378 - acc: 0.4900 - val_loss: 1.2532 - val_acc: 0.4500\n",
      "Epoch 2/2\n",
      "5208/5208 [==============================] - 3s - loss: 1.0638 - acc: 0.5173 - val_loss: 1.1391 - val_acc: 0.4538\n",
      "Train on 5208 samples, validate on 2411 samples\n",
      "Epoch 1/5\n",
      "5208/5208 [==============================] - 3s - loss: 0.9942 - acc: 0.5503 - val_loss: 1.2072 - val_acc: 0.4305\n",
      "Epoch 2/5\n",
      "5208/5208 [==============================] - 3s - loss: 0.9006 - acc: 0.6052 - val_loss: 1.1761 - val_acc: 0.4430\n",
      "Epoch 3/5\n",
      "5208/5208 [==============================] - 3s - loss: 0.8028 - acc: 0.6455 - val_loss: 1.2069 - val_acc: 0.4496\n",
      "Epoch 4/5\n",
      "5208/5208 [==============================] - 3s - loss: 0.7396 - acc: 0.6872 - val_loss: 1.2507 - val_acc: 0.4363\n",
      "Epoch 5/5\n",
      "5208/5208 [==============================] - 3s - loss: 0.6610 - acc: 0.7250 - val_loss: 1.4080 - val_acc: 0.4405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4491e5c710>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(features, labels, batch_size=64, shuffle=True ,nb_epoch=2,validation_data=(features_val, labels_val),verbose=1)\n",
    "bn_model.optimizer.lr = 0.0001\n",
    "bn_model.fit(features, labels, batch_size=64, shuffle=True ,nb_epoch=2,validation_data=(features_val, labels_val),verbose=1)\n",
    "bn_model.optimizer.lr = 0.00001\n",
    "bn_model.fit(features, labels, batch_size=64, shuffle=True ,nb_epoch=5,validation_data=(features_val, labels_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.5\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bn_model.fit(features, labels, batch_size=32, shuffle=True ,nb_epoch=5,validation_data=(features_val, labels_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p=0.5\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "bn_model.fit(features, labels, batch_size=32, shuffle=True ,nb_epoch=10,validation_data=(features_val, labels_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p=0.5\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "bn_model.fit(features, labels, batch_size=32, shuffle=True ,nb_epoch=5,validation_data=(features_val, labels_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p=0.5\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "bn_model.fit(features, labels, batch_size=32, shuffle=True ,nb_epoch=5,validation_data=(features_val, labels_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p=0.5\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "bn_model.fit(features, labels, batch_size=32, shuffle=True ,nb_epoch=5,validation_data=(features_val, labels_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p=0.6\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "bn_model.fit(features, labels, batch_size=32, shuffle=True ,nb_epoch=5,validation_data=(features_val, labels_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p=0.7\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "bn_model.fit(features, labels, batch_size=32, shuffle=True ,nb_epoch=5,validation_data=(features_val, labels_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p=0.7\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "bn_model.fit(features, labels, batch_size=32, shuffle=True ,nb_epoch=1,validation_data=(features_val, labels_val),verbose=1)\n",
    "bn_model.optimizer.lr = 0.001\n",
    "bn_model.fit(features, labels, batch_size=32, shuffle=True ,nb_epoch=1,validation_data=(features_val, labels_val),verbose=1)\n",
    "bn_model.optimizer.lr = 0.00001\n",
    "bn_model.fit(features, labels, batch_size=32, shuffle=True ,nb_epoch=3,validation_data=(features_val, labels_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p=0.7\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "bn_model.fit(features, labels, batch_size=32, shuffle=True ,nb_epoch=1,validation_data=(features_val, labels_val),verbose=1)\n",
    "bn_model.optimizer.lr = 0.00001\n",
    "bn_model.fit(features, labels, batch_size=32, shuffle=True ,nb_epoch=3,validation_data=(features_val, labels_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p=0.1\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "bn_model.fit(features, labels, batch_size=32, shuffle=True ,nb_epoch=5,validation_data=(features_val, labels_val),verbose=1)\n",
    "bn_model.optimizer.lr = 0.001\n",
    "bn_model.fit(features, labels, batch_size=32, shuffle=True ,nb_epoch=1,validation_data=(features_val, labels_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p=0.9\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "bn_model.fit(features, labels, batch_size=32, shuffle=True ,nb_epoch=1,validation_data=(features_val, labels_val),verbose=1)\n",
    "bn_model.optimizer.lr=0.001\n",
    "bn_model.fit(features, labels, batch_size=32, shuffle=True ,nb_epoch=2,validation_data=(features_val, labels_val),verbose=1)\n",
    "bn_model.optimizer.lr=0.0001\n",
    "bn_model.fit(features, labels, batch_size=32, shuffle=True ,nb_epoch=3,validation_data=(features_val, labels_val),verbose=1)\n",
    "bn_model.optimizer.lr=0.00001\n",
    "bn_model.fit(features, labels, batch_size=32, shuffle=True ,nb_epoch=3,validation_data=(features_val, labels_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "print inspect.getsource(bn_model.evaluate_generator)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
