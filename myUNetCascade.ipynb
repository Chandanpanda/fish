{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-03-30 03:33:30--  https://www.dropbox.com/s/aoykiiuu669igxa/step1_weights.caffemodel?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.64.1\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.64.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://dl.dropboxusercontent.com/content_link/OtbCLJcqvETzCKFzyi661BpUWwe1tfLsuyjSbutDHG7MKVnth30ftQJDC6jz52rl/file [following]\n",
      "--2017-03-30 03:33:30--  https://dl.dropboxusercontent.com/content_link/OtbCLJcqvETzCKFzyi661BpUWwe1tfLsuyjSbutDHG7MKVnth30ftQJDC6jz52rl/file\n",
      "Resolving dl.dropboxusercontent.com (dl.dropboxusercontent.com)... 162.125.64.6\n",
      "Connecting to dl.dropboxusercontent.com (dl.dropboxusercontent.com)|162.125.64.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 124128410 (118M) [application/octet-stream]\n",
      "Saving to: ‘models/step1_weights.caffemodel’\n",
      "\n",
      "models/step1_weight 100%[===================>] 118.38M  45.5MB/s    in 2.6s    \n",
      "\n",
      "2017-03-30 03:33:34 (45.5 MB/s) - ‘models/step1_weights.caffemodel’ saved [124128410/124128410]\n",
      "\n",
      "--2017-03-30 03:33:35--  https://www.dropbox.com/s/ql10c37d7ura23l/step2_weights.caffemodel?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.64.1\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.64.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://dl.dropboxusercontent.com/content_link/NMjQF9RF4ABoIwaNlBFoe1nLpuvJaHKnhc3bhlu6pzRItqLKGr3EqxmBWWEhQzCV/file [following]\n",
      "--2017-03-30 03:33:36--  https://dl.dropboxusercontent.com/content_link/NMjQF9RF4ABoIwaNlBFoe1nLpuvJaHKnhc3bhlu6pzRItqLKGr3EqxmBWWEhQzCV/file\n",
      "Resolving dl.dropboxusercontent.com (dl.dropboxusercontent.com)... 162.125.64.6\n",
      "Connecting to dl.dropboxusercontent.com (dl.dropboxusercontent.com)|162.125.64.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 124127892 (118M) [application/octet-stream]\n",
      "Saving to: ‘models/step2_weights.caffemodel’\n",
      "\n",
      "models/step2_weight 100%[===================>] 118.38M  54.2MB/s    in 2.2s    \n",
      "\n",
      "2017-03-30 03:33:39 (54.2 MB/s) - ‘models/step2_weights.caffemodel’ saved [124127892/124127892]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get model weights (step1 and step2 models)\n",
    "!wget --tries=2 -O models/step1_weights.caffemodel https://www.dropbox.com/s/aoykiiuu669igxa/step1_weights.caffemodel?dl=0\n",
    "!wget --tries=2 -O models/step2_weights.caffemodel https://www.dropbox.com/s/ql10c37d7ura23l/step2_weights.caffemodel?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STEP1_DEPLOY_PROTOTXT = \"../models/cascadedfcn/step1/step1_deploy.prototxt\"\n",
    "STEP1_MODEL_WEIGHTS   = \"../models/cascadedfcn/step1/step1_weights.caffemodel\"\n",
    "STEP2_DEPLOY_PROTOTXT = \"../models/cascadedfcn/step2/step2_deploy.prototxt\"\n",
    "STEP2_MODEL_WEIGHTS   = \"../models/cascadedfcn/step2/step2_weights.caffemodel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STEP1_DEPLOY_PROTOTXT = \"../models/cascadedfcn/step1/step1_deploy.prototxt\"\n",
    "STEP1_MODEL_WEIGHTS   = \"../models/cascadedfcn/step1/step1_weights.caffemodel\"\n",
    "STEP2_DEPLOY_PROTOTXT = \"../models/cascadedfcn/step2/step2_deploy.prototxt\"\n",
    "STEP2_MODEL_WEIGHTS   = \"../models/cascadedfcn/step2/step2_weights.caffemodel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5f0640039a43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mIMG_DTYPE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mSEG_DTYPE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdicom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnatsort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "IMG_DTYPE = np.float\n",
    "SEG_DTYPE = np.uint8\n",
    "\n",
    "import dicom\n",
    "import natsort\n",
    "import glob, os\n",
    "import re\n",
    "def read_dicom_series(directory, filepattern = \"image_*\"):\n",
    "    \"\"\" Reads a DICOM Series files in the given directory. \n",
    "    Only filesnames matching filepattern will be considered\"\"\"\n",
    "    \n",
    "    if not os.path.exists(directory) or not os.path.isdir(directory):\n",
    "        raise ValueError(\"Given directory does not exist or is a file : \"+str(directory))\n",
    "    print '\\tRead Dicom',directory\n",
    "    lstFilesDCM = natsort.natsorted(glob.glob(os.path.join(directory, filepattern)))\n",
    "    print '\\tLength dicom series',len(lstFilesDCM)\n",
    "    # Get ref file\n",
    "    RefDs = dicom.read_file(lstFilesDCM[0])\n",
    "    # Load dimensions based on the number of rows, columns, and slices (along the Z axis)\n",
    "    ConstPixelDims = (int(RefDs.Rows), int(RefDs.Columns), len(lstFilesDCM))\n",
    "    # The array is sized based on 'ConstPixelDims'\n",
    "    ArrayDicom = np.zeros(ConstPixelDims, dtype=RefDs.pixel_array.dtype)\n",
    "\n",
    "    # loop through all the DICOM files\n",
    "    for filenameDCM in lstFilesDCM:\n",
    "        # read the file\n",
    "        ds = dicom.read_file(filenameDCM)\n",
    "        # store the raw image data\n",
    "        ArrayDicom[:, :, lstFilesDCM.index(filenameDCM)] = ds.pixel_array\n",
    "\n",
    "    return ArrayDicom\n",
    "\n",
    "def read_liver_lesion_masks(masks_dirname):\n",
    "    \"\"\"Since 3DIRCAD provides an individual mask for each tissue type (in DICOM series format),\n",
    "    we merge multiple tissue types into one Tumor mask, and merge this mask with the liver mask\n",
    "    \n",
    "    Args:\n",
    "        masks_dirname : MASKS_DICOM directory containing multiple DICOM series directories, \n",
    "                        one for each labelled mask\n",
    "    Returns:\n",
    "        numpy array with 0's for background pixels, 1's for liver pixels and 2's for tumor pixels\n",
    "    \"\"\"\n",
    "    tumor_volume = None\n",
    "    liver_volume = None\n",
    "    \n",
    "    # For each relevant organ in the current volume\n",
    "    for organ in os.listdir(masks_dirname):\n",
    "        organ_path = os.path.join(masks_dirname,organ)\n",
    "        if not os.path.isdir(organ_path):\n",
    "            continue\n",
    "        \n",
    "        organ = organ.lower()\n",
    "        \n",
    "        if organ.startswith(\"livertumor\") or re.match(\"liver.yst.*\", organ) or organ.startswith(\"stone\") or organ.startswith(\"metastasecto\") :\n",
    "            print 'Organ',masks_dirname,organ\n",
    "            current_tumor = read_dicom_series(organ_path)\n",
    "            current_tumor = np.clip(current_tumor,0,1)\n",
    "            # Merge different tumor masks into a single mask volume\n",
    "            tumor_volume = current_tumor if tumor_volume is None else np.logical_or(tumor_volume,current_tumor)\n",
    "        elif organ == 'liver':\n",
    "            print 'Organ',masks_dirname,organ\n",
    "            liver_volume = read_dicom_series(organ_path)\n",
    "            liver_volume = np.clip(liver_volume, 0, 1)\n",
    "    \n",
    "    # Merge liver and tumor into 1 volume with background=0, liver=1, tumor=2\n",
    "    label_volume = np.zeros(liver_volume.shape)\n",
    "    label_volume[liver_volume==1]=1\n",
    "    label_volume[tumor_volume==1]=2\n",
    "    return label_volume    \n",
    "            \n",
    "def stat(array):\n",
    "    print 'min',np.min(array),'max',np.max(array),'median',np.median(array),'avg',np.mean(array)\n",
    "def imshow(*args,**kwargs):\n",
    "    \"\"\" Handy function to show multiple plots in on row, possibly with different cmaps and titles\n",
    "    Usage: \n",
    "    imshow(img1, title=\"myPlot\")\n",
    "    imshow(img1,img2, title=['title1','title2'])\n",
    "    imshow(img1,img2, cmap='hot')\n",
    "    imshow(img1,img2,cmap=['gray','Blues']) \"\"\"\n",
    "    cmap = kwargs.get('cmap', 'gray')\n",
    "    title= kwargs.get('title','')\n",
    "    if len(args)==0:\n",
    "        raise ValueError(\"No images given to imshow\")\n",
    "    elif len(args)==1:\n",
    "        plt.title(title)\n",
    "        plt.imshow(args[0], interpolation='none')\n",
    "    else:\n",
    "        n=len(args)\n",
    "        if type(cmap)==str:\n",
    "            cmap = [cmap]*n\n",
    "        if type(title)==str:\n",
    "            title= [title]*n\n",
    "        plt.figure(figsize=(n*5,10))\n",
    "        for i in range(n):\n",
    "            plt.subplot(1,n,i+1)\n",
    "            plt.title(title[i])\n",
    "            plt.imshow(args[i], cmap[i])\n",
    "    plt.show()\n",
    "    \n",
    "def to_scale(img, shape=None):\n",
    "\n",
    "    height, width = shape\n",
    "    if img.dtype == SEG_DTYPE:\n",
    "        return scipy.misc.imresize(img,(height,width),interp=\"nearest\").astype(SEG_DTYPE)\n",
    "    elif img.dtype == IMG_DTYPE:\n",
    "        max_ = np.max(img)\n",
    "        factor = 255.0/max_ if max_ != 0 else 1\n",
    "        return (scipy.misc.imresize(img,(height,width),interp=\"nearest\")/factor).astype(IMG_DTYPE)\n",
    "    else:\n",
    "        raise TypeError('Error. To scale the image array, its type must be np.uint8 or np.float64. (' + str(img.dtype) + ')')\n",
    "\n",
    "\n",
    "def normalize_image(img):\n",
    "    \"\"\" Normalize image values to [0,1] \"\"\"\n",
    "    min_, max_ = float(np.min(img)), float(np.max(img))\n",
    "    return (img - min_) / (max_ - min_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_lbl_slice(lbl_slc):\n",
    "    \"\"\" Preprocess ground truth slice to match output prediction of the network in terms \n",
    "    of size and orientation.\n",
    "    \n",
    "    Args:\n",
    "        lbl_slc: raw label/ground-truth slice\n",
    "    Return:\n",
    "        Preprocessed label slice\"\"\"\n",
    "    lbl_slc = lbl_slc.astype(SEG_DTYPE)\n",
    "    #downscale the label slc for comparison with the prediction\n",
    "    lbl_slc = to_scale(lbl_slc , (388, 388))\n",
    "    return lbl_slc\n",
    "\n",
    "def step1_preprocess_img_slice(img_slc):\n",
    "    \"\"\"\n",
    "    Preprocesses the image 3d volumes by performing the following :\n",
    "    1- Rotate the input volume so the the liver is on the left, spine is at the bottom of the image\n",
    "    2- Set pixels with hounsfield value great than 1200, to zero.\n",
    "    3- Clip all hounsfield values to the range [-100, 400]\n",
    "    4- Normalize values to [0, 1]\n",
    "    5- Rescale img and label slices to 388x388\n",
    "    6- Pad img slices with 92 pixels on all sides (so total shape is 572x572)\n",
    "    \n",
    "    Args:\n",
    "        img_slc: raw image slice\n",
    "    Return:\n",
    "        Preprocessed image slice\n",
    "    \"\"\"      \n",
    "    img_slc   = img_slc.astype(IMG_DTYPE)\n",
    "    img_slc[img_slc>1200] = 0\n",
    "    img_slc   = np.clip(img_slc, -100, 400)    \n",
    "    img_slc   = normalize_image(img_slc)\n",
    "    img_slc   = to_scale(img_slc, (388,388))\n",
    "    img_slc   = np.pad(img_slc,((92,92),(92,92)),mode='reflect')\n",
    "    if False:\n",
    "        img_slc = histeq_processor(img_slc)\n",
    "\n",
    "    return img_slc\n",
    "\n",
    "def step2_preprocess_img_slice(img_p, step1_pred):\n",
    "    \"\"\" Preprocess img slice using the prediction image from step1, by performing\n",
    "    the following :\n",
    "    1- Set non-liver pixels to 0\n",
    "    2- Calculate liver bounding box\n",
    "    3- Crop the liver patch in the input img\n",
    "    4- Resize (usually upscale) the liver patch to the full network input size 388x388\n",
    "    5- Pad image slice with 92 on all sides\n",
    "    \n",
    "    Args:\n",
    "        img_p: Preprocessed image slice\n",
    "        step1_pred: prediction image from step1\n",
    "    Return: \n",
    "        The liver patch and the bounding box coordinate relative to the original img coordinates\"\"\"\n",
    "    \n",
    "    img = img_p[92:-92,92:-92]\n",
    "    pred = step1_pred.astype(SEG_DTYPE)\n",
    "    \n",
    "    # Remove background !\n",
    "    img = np.multiply(img,np.clip(pred,0,1))\n",
    "    # get patch size\n",
    "    col_maxes = np.max(pred, axis=0) # a row\n",
    "    row_maxes = np.max(pred, axis=1)# a column\n",
    "\n",
    "    nonzero_colmaxes = np.nonzero(col_maxes)[0]\n",
    "    nonzero_rowmaxes = np.nonzero(row_maxes)[0]\n",
    "\n",
    "    x1, x2 = nonzero_colmaxes[0], nonzero_colmaxes[-1]\n",
    "    y1, y2 = nonzero_rowmaxes[0], nonzero_rowmaxes[-1]\n",
    "    width = x2-x1\n",
    "    height= y2-y1\n",
    "    MIN_WIDTH = 60\n",
    "    MIN_HEIGHT= 60\n",
    "    x_pad = (MIN_WIDTH - width) / 2 if width < MIN_WIDTH else 0\n",
    "    y_pad = (MIN_HEIGHT - height)/2 if height < MIN_HEIGHT else 0\n",
    "\n",
    "    x1 = max(0, x1-x_pad)\n",
    "    x2 = min(img.shape[1], x2+x_pad)\n",
    "    y1 = max(0, y1-y_pad)\n",
    "    y2 = min(img.shape[0], y2+y_pad)\n",
    "\n",
    "    img = img[y1:y2+1, x1:x2+1]\n",
    "    pred = pred[y1:y2+1, x1:x2+1]\n",
    "\n",
    "    img = to_scale(img, (388,388))\n",
    "    pred = to_scale(pred, (388,388))\n",
    "    # All non-lesion is background\n",
    "    pred[pred==1]=0\n",
    "    #Lesion label becomes 1\n",
    "    pred[pred==2]=1\n",
    "\n",
    "    # Now do padding for UNET, which takes 572x572\n",
    "    #pred=np.pad(pred,((92,92),(92,92)),mode='reflect')\n",
    "    img=np.pad(img,92,mode='reflect')\n",
    "    return img, (x1,x2,y1,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download image 17 of 3DIRCAdb1 dataset\n",
    "!wget http://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.17.zip -O 3Dircadb1.17.zip\n",
    "# Unzip into test_image\n",
    "!unzip -o 3Dircadb1.17.zip -d test_image/\n",
    "# Unzip the image CT volume\n",
    "!unzip -o test_image/3Dircadb1.17/PATIENT_DICOM.zip -d test_image/3Dircadb1.17/\n",
    "# Unzip the label masks\n",
    "!unzip -o test_image/3Dircadb1.17/MASKS_DICOM.zip -d test_image/3Dircadb1.17/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img=read_dicom_series(\"test_image/3Dircadb1.17/PATIENT_DICOM/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbl=read_liver_lesion_masks(\"test_image/3Dircadb1.17/MASKS_DICOM/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img.shape, lbl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for s in range(50,100,20):\n",
    "    imshow(img[...,s],lbl[...,s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for s in range(50,100,20):\n",
    "    print s\n",
    "    img_p = step1_preprocess_img_slice(img[...,s])\n",
    "    lbl_p = preprocess_lbl_slice(lbl[...,s])\n",
    "    imshow(img_p,lbl_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare a test slice\n",
    "S = 90\n",
    "img_p = step1_preprocess_img_slice(img[...,S])\n",
    "lbl_p = preprocess_lbl_slice(lbl[...,S])\n",
    "imshow(img_p,lbl_p,title=['Test image','Ground truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import caffe as caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not open file ../models/cascadedfcn/step1/step1_deploy.prototxt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c1a2287a0567>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTEP1_DEPLOY_PROTOTXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTEP1_MODEL_WEIGHTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not open file ../models/cascadedfcn/step1/step1_deploy.prototxt"
     ]
    }
   ],
   "source": [
    "# Load network\n",
    "net1 = caffe.Net(STEP1_DEPLOY_PROTOTXT, STEP1_MODEL_WEIGHTS, caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "net1.blobs['data'].data[0,0,...] = img_p\n",
    "pred = net1.forward()['prob'][0,1] > 0.5\n",
    "print pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Free up memory of step1 network\n",
    "del net1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare liver patch for step2\n",
    "# net1 output is used to determine the predicted liver bounding box\n",
    "img_p2, bbox = step2_preprocess_img_slice(img_p, pred)\n",
    "imshow(img_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load step2 network\n",
    "net2 = caffe.Net(STEP2_DEPLOY_PROTOTXT, STEP2_MODEL_WEIGHTS, caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "net2.blobs['data'].data[0,0,...] = img_p2\n",
    "pred2 = net2.forward()['prob'][0,1]\n",
    "print pred2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize result\n",
    "\n",
    "# extract liver portion as predicted by net1\n",
    "x1,x2,y1,y2 = bbox\n",
    "lbl_p_liver = lbl_p[y1:y2,x1:x2]\n",
    "# Set labels to 0 and 1\n",
    "lbl_p_liver[lbl_p_liver==1]=0\n",
    "lbl_p_liver[lbl_p_liver==2]=1\n",
    "imshow(img_p2[92:-92,92:-92],lbl_p_liver, pred2>0.5)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
