{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SQUEEZENET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Conv2D, MaxPooling2D, UpSampling2D, GlobalMaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from random import uniform\n",
    "import bcolz\n",
    "from time import *\n",
    "from keras.layers import merge\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers import Input, Dense\n",
    "import math\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils as u\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "import resnet50; reload(resnet50)\n",
    "from resnet50 import Resnet50\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import myFunctionsv3; reload(myFunctionsv3)\n",
    "from myFunctionsv3 import *\n",
    "from  keras.applications.resnet50 import ResNet50\n",
    "from squeezenet import SqueezeNet\n",
    "\n",
    "import gc\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nf=128; p=0.01\n",
    "def get_lrg_layers():\n",
    "    \n",
    "    inp = Input((21, 39, 512))\n",
    "    x = BatchNormalization(axis=1)(inp)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(nf,(1,1), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(nf,(1,1), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(nf,(1,1), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    \n",
    "    x_15 = Conv2D(15,(3,3), activation='relu', padding='same')(x)\n",
    "    x_15 = BatchNormalization(axis=1)(x_15)\n",
    "    x_15 = GlobalMaxPooling2D()(x_15)\n",
    "    x_sig_15 = Activation('sigmoid')(x_15)\n",
    "    \n",
    "    x_4 = Conv2D(4,(3,3), activation='relu', padding='same')(x)\n",
    "    x_4 = BatchNormalization(axis=1)(x_4)\n",
    "    x_4 = GlobalMaxPooling2D()(x_4)\n",
    "    x_sof_4 = Activation('sigmoid')(x_4)\n",
    "    \n",
    "    x_2 = Conv2D(3,(3,3), activation='relu', padding='same')(x)\n",
    "    x_2 = BatchNormalization(axis=1)(x_2)\n",
    "    x_2 = GlobalMaxPooling2D()(x_2)\n",
    "    x_sof_2 = Activation('softmax')(x_2)\n",
    "    \n",
    "    model = Model([inp], [x_sig_15, x_sof_4, x_sof_2])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model = get_lrg_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 21, 39, 512)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 21, 39, 512)   84          input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 10, 19, 512)   0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 10, 19, 128)   65664       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 10, 19, 128)   40          conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 10, 19, 128)   147584      batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 10, 19, 128)   40          conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 10, 19, 128)   147584      batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 10, 19, 128)   40          conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 5, 9, 128)     0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 5, 9, 128)     16512       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 5, 9, 128)     20          conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 5, 9, 128)     147584      batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 5, 9, 128)     20          conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 5, 9, 128)     147584      batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 5, 9, 128)     20          conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 2, 4, 128)     0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 2, 4, 128)     16512       max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 2, 4, 128)     8           conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 2, 4, 128)     147584      batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 2, 4, 128)     8           conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 2, 4, 15)      17295       batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 2, 4, 4)       4612        batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 2, 4, 3)       3459        batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 2, 4, 15)      8           conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, 2, 4, 4)       8           conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, 2, 4, 3)       8           conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalMa (None, 15)            0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling2d_2 (GlobalMa (None, 4)             0           batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling2d_3 (GlobalMa (None, 3)             0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 15)            0           global_max_pooling2d_1[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 4)             0           global_max_pooling2d_2[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 3)             0           global_max_pooling2d_3[0][0]     \n",
      "====================================================================================================\n",
      "Total params: 862,278\n",
      "Trainable params: 862,126\n",
      "Non-trainable params: 152\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lrg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27062"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def addZeroLabelCannula(y):\n",
    "    temp = sum(np.transpose(y)[[1,2,3,4],:]) \n",
    "    temp[temp>1]=1\n",
    "    temp = 1 - temp \n",
    "    final = np.hstack((y[:,[1,2,3,4]],np.expand_dims(temp,1)))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addZeroLabelForceps(y):\n",
    "    temp = sum(np.transpose(y)[[7,8],:]) \n",
    "    temp[temp>1]=1\n",
    "    temp = 1 - temp \n",
    "    final = np.hstack((y[:,[7,8]],np.expand_dims(temp,1)))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_generator(files):\n",
    "    while 1:\n",
    "        for i in range(len(files)):\n",
    "            conv_trn_feat = load_array('/cat/home/ubuntu/cat/out/features/train/'+files[i]+'_sqznt.dat')\n",
    "            label = load_array('/cat/home/ubuntu/cat/in/train/folds/'+files[i]+'_labels.dat')\n",
    "            totalFrames = label.shape[0]\n",
    "            batches = int(totalFrames/batch_size)\n",
    "            for j in range(batches):\n",
    "                x = conv_trn_feat[j*batch_size:(j+1)*batch_size,]\n",
    "                y = label[j*batch_size:(j+1)*batch_size,2:23]\n",
    "                \n",
    "                y1 = y[:,[0,5,6,9,10,11,12,13,14,15,16,17,18,19,20]] #remaining\n",
    "                \n",
    "                #y2 = addZeroLabelCannula(y)\n",
    "                y2 = y[:,[1,2,3,4]]\n",
    "                #Charleux canula, hydrodissection canula, Rycroft canula, viscoelastic cannula\n",
    "                \n",
    "                y3 = addZeroLabelForceps(y)\n",
    "                #Bonn forceps, capsulorhexis forceps\n",
    "                \n",
    "                yield (x, [y1,y2,y3])\n",
    "            del(conv_trn_feat,label)\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_generator_val(files):\n",
    "    while 1:\n",
    "        for i in range(len(files)):\n",
    "            conv_val_feat = load_array('/cat/home/ubuntu/cat/out/features/train/'+files[i]+'_sqznt.dat')\n",
    "            label_val = load_array('/cat/home/ubuntu/cat/in/train/labels/'+files[i]+'_labels.dat')\n",
    "            totalFrames = label_val.shape[0]\n",
    "            batches = int(totalFrames/batch_size)\n",
    "            for j in range(batches): \n",
    "                x = conv_val_feat[j*batch_size:(j+1)*batch_size,]\n",
    "                y = label_val[j*batch_size:(j+1)*batch_size,2:23]\n",
    "                \n",
    "                y1 = y[:,[0,5,6,9,10,11,12,13,14,15,16,17,18,19,20]] #remaining\n",
    "                \n",
    "                #y2 = addZeroLabelCannula(y)\n",
    "                y2 = y[:,[1,2,3,4]]\n",
    "                #Charleux canula, hydrodissection canula, Rycroft canula, viscoelastic cannula\n",
    "                \n",
    "                y3 = addZeroLabelForceps(y)\n",
    "                #Bonn forceps, capsulorhexis forceps\n",
    "                \n",
    "                yield (x, [y1,y2,y3])\n",
    "            del(conv_val_feat,label_val)\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107050\n"
     ]
    }
   ],
   "source": [
    "files = ['trainfold1','trainfold2','trainfold3','trainfold4','trainfold5',\n",
    "         'trainfold6','trainfold7','trainfold8','trainfold9','trainfold0']\n",
    "totalCount=0\n",
    "for i in range(len(files)):\n",
    "    labelFile = load_array('/cat/home/ubuntu/cat/in/train/folds/'+files[i]+'_labels.dat')\n",
    "    totalCount += labelFile.shape[0]\n",
    "    del(labelFile)\n",
    "print(totalCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30775\n"
     ]
    }
   ],
   "source": [
    "files_val = ['train03_val_minus_0p5','train04_val_minus_0p5','train10_val_minus_0p5','train18_val_minus_0p5',\n",
    "         'train21_val_minus_0p5','train14_val_minus_0p5','train19_val_minus_0p5','train24_val_minus_0p5']\n",
    "totalCountVal=0\n",
    "for i in range(len(files_val)):\n",
    "    labelFile = load_array('/cat/home/ubuntu/cat/in/train/labels/'+files_val[i]+'_labels.dat')\n",
    "    totalCountVal += labelFile.shape[0]\n",
    "    del(labelFile)\n",
    "print(totalCountVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model.compile(Adam(lr=0.01), loss=['binary_crossentropy', 'binary_crossentropy','binary_crossentropy'], metrics=['accuracy'],\n",
    "             loss_weights=[0.45, 0.30,0.25])    \n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  app.launch_new_instance()\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., epochs=3, validation_data=<generator..., steps_per_epoch=1672, validation_steps=480)`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1672/1672 [==============================] - 2090s - loss: 0.1831 - activation_1_loss: 0.2280 - activation_2_loss: 0.1990 - activation_3_loss: 0.0831 - activation_1_acc: 0.9197 - activation_2_acc: 0.9381 - activation_3_acc: 0.9730 - val_loss: 0.1245 - val_activation_1_loss: 0.1176 - val_activation_2_loss: 0.1423 - val_activation_3_loss: 0.1154 - val_activation_1_acc: 0.9596 - val_activation_2_acc: 0.9681 - val_activation_3_acc: 0.9753\n",
      "Epoch 2/3\n",
      "1672/1672 [==============================] - 1938s - loss: 0.0875 - activation_1_loss: 0.0942 - activation_2_loss: 0.1213 - activation_3_loss: 0.0348 - activation_1_acc: 0.9710 - activation_2_acc: 0.9715 - activation_3_acc: 0.9887 - val_loss: 0.1136 - val_activation_1_loss: 0.0879 - val_activation_2_loss: 0.1403 - val_activation_3_loss: 0.1280 - val_activation_1_acc: 0.9716 - val_activation_2_acc: 0.9666 - val_activation_3_acc: 0.9545\n",
      "Epoch 3/3\n",
      "1672/1672 [==============================] - 1979s - loss: 0.0578 - activation_1_loss: 0.0540 - activation_2_loss: 0.0930 - activation_3_loss: 0.0225 - activation_1_acc: 0.9833 - activation_2_acc: 0.9747 - activation_3_acc: 0.9928 - val_loss: 0.0918 - val_activation_1_loss: 0.0662 - val_activation_2_loss: 0.1440 - val_activation_3_loss: 0.0753 - val_activation_1_acc: 0.9795 - val_activation_2_acc: 0.9618 - val_activation_3_acc: 0.9767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c13520490>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrg_model.fit_generator(feature_generator(files),steps_per_epoch=totalCount/batch_size,\n",
    "                                  nb_epoch=3,validation_data=feature_generator_val(files_val),\n",
    "                        validation_steps=totalCountVal/batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1,min_delta=1e-4),\n",
    "             ReduceLROnPlateau(monitor='val_loss',factor=0.1, patience=2, cooldown=2, verbose=1),\n",
    "                 ModelCheckpoint(filepath='../out/weights/sqznt_weights_folds_8_9_128_Iteration11.hdf5',\n",
    "                                 save_best_only=True,save_weights_only=True)]\n",
    "K.set_value(lrg_model.optimizer.lr, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., steps_per_epoch=1672, epochs=50, callbacks=[<keras.ca..., validation_steps=480)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1672/1672 [==============================] - 2142s - loss: 0.0292 - activation_1_loss: 0.0239 - activation_2_loss: 0.0540 - activation_3_loss: 0.0088 - activation_1_acc: 0.9922 - activation_2_acc: 0.9835 - activation_3_acc: 0.9974 - val_loss: 0.0761 - val_activation_1_loss: 0.0507 - val_activation_2_loss: 0.1216 - val_activation_3_loss: 0.0671 - val_activation_1_acc: 0.9827 - val_activation_2_acc: 0.9693 - val_activation_3_acc: 0.9844\n",
      "Epoch 2/50\n",
      "1672/1672 [==============================] - 2012s - loss: 0.0221 - activation_1_loss: 0.0189 - activation_2_loss: 0.0403 - activation_3_loss: 0.0060 - activation_1_acc: 0.9937 - activation_2_acc: 0.9870 - activation_3_acc: 0.9984 - val_loss: 0.0849 - val_activation_1_loss: 0.0529 - val_activation_2_loss: 0.1442 - val_activation_3_loss: 0.0711 - val_activation_1_acc: 0.9829 - val_activation_2_acc: 0.9678 - val_activation_3_acc: 0.9840\n",
      "Epoch 3/50\n",
      "1672/1672 [==============================] - 2029s - loss: 0.0170 - activation_1_loss: 0.0156 - activation_2_loss: 0.0298 - activation_3_loss: 0.0041 - activation_1_acc: 0.9949 - activation_2_acc: 0.9904 - activation_3_acc: 0.9989 - val_loss: 0.0957 - val_activation_1_loss: 0.0606 - val_activation_2_loss: 0.1603 - val_activation_3_loss: 0.0813 - val_activation_1_acc: 0.9820 - val_activation_2_acc: 0.9656 - val_activation_3_acc: 0.9817\n",
      "Epoch 4/50\n",
      "1671/1672 [============================>.] - ETA: 0s - loss: 0.0132 - activation_1_loss: 0.0130 - activation_2_loss: 0.0225 - activation_3_loss: 0.0026 - activation_1_acc: 0.9957 - activation_2_acc: 0.9932 - activation_3_acc: 0.9994\n",
      "Epoch 00003: reducing learning rate to 0.00010000000475.\n",
      "1672/1672 [==============================] - 1935s - loss: 0.0132 - activation_1_loss: 0.0130 - activation_2_loss: 0.0225 - activation_3_loss: 0.0026 - activation_1_acc: 0.9957 - activation_2_acc: 0.9932 - activation_3_acc: 0.9994 - val_loss: 0.1018 - val_activation_1_loss: 0.0604 - val_activation_2_loss: 0.1772 - val_activation_3_loss: 0.0858 - val_activation_1_acc: 0.9830 - val_activation_2_acc: 0.9624 - val_activation_3_acc: 0.9843\n",
      "Epoch 5/50\n",
      "1672/1672 [==============================] - 2669s - loss: 0.0097 - activation_1_loss: 0.0099 - activation_2_loss: 0.0160 - activation_3_loss: 0.0017 - activation_1_acc: 0.9968 - activation_2_acc: 0.9955 - activation_3_acc: 0.9996 - val_loss: 0.0950 - val_activation_1_loss: 0.0581 - val_activation_2_loss: 0.1564 - val_activation_3_loss: 0.0878 - val_activation_1_acc: 0.9834 - val_activation_2_acc: 0.9683 - val_activation_3_acc: 0.9837\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "#Benchmark loss: 0.0677\n",
    "history = lrg_model.fit_generator(feature_generator(files),steps_per_epoch=totalCount/batch_size,\n",
    "                                  nb_epoch=50,callbacks=callbacks,\n",
    "                                  validation_data=feature_generator_val(files_val),validation_steps=totalCountVal/batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrg_model.save_weights('../out/weights/sqznt_weights_folds_8_9_128_Iteration11_final_epoch.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take backup of weights before you rerun the above code!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAikAAAGHCAYAAAB1bcIdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFylmZmZWS/8Hg9/4zprik+MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1fcd7c2250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'activation_1_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-ca42be0b9b4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'activation_1_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_activation_1_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy 15'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'activation_1_acc'"
     ]
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['activation_1_acc'])\n",
    "plt.plot(history.history['val_activation_1_acc'])\n",
    "plt.title('model accuracy 15')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['activation_2_acc'])\n",
    "plt.plot(history.history['val_activation_2_acc'])\n",
    "plt.title('model accuracy 2')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['activation_3_acc'])\n",
    "plt.plot(history.history['val_activation_3_acc'])\n",
    "plt.title('model accuracy 3')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Temporary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from densenet import DenseNet, DenseNetImageNet121\n",
    "dense = DenseNetImageNet121(input_shape=(360,640,3),weights='imagenet',include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs = dense.input, outputs = dense.layers[-18].output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDenseNetFeatures(path,name):\n",
    "    rgb_hires = load_array(path + name + '_hires.dat')\n",
    "    conv_feat = model.predict(rgb_hires, batch_size=32, verbose=0)\n",
    "    save_array('/cat/home/ubuntu/cat/out/features/train/'+name+'_dnsnt.dat',conv_feat)\n",
    "    del(conv_feat,rgb_hires)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = ['trainfold1','trainfold2','trainfold3','trainfold4','trainfold5',\n",
    "         'trainfold6','trainfold7','trainfold8','trainfold9','trainfold0'] \n",
    "\n",
    "for i in tqdm(range(len(files))):\n",
    "    createDenseNetFeatures('/cat/home/ubuntu/cat/in/train/folds/',files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model.load_weights('/cat/home/ubuntu/cat/out/weights/sqznt_weights_folds_8_9_128_Iteration10.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame=155\n",
    "pred = lrg_model.predict(np.expand_dims(conv_val_feat[frame],0))\n",
    "pred = np.hstack((pred[0],pred[1],pred[2]))\n",
    "pred.shape\n",
    "np.round(pred[0],4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 0,5,6,9,10,11,12,13,14,15,16,17,18,19,20,1,2,3,4,7,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_temp = np.copy(labels_val[:,2:23])\n",
    "labels_temp[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]] = labels_temp[:,[0,5,6,9,10,11,12,13,14,15,16,17,18,19,20,1,2,3,4,7,8]]\n",
    "labels_temp[frame,0:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28900, 21) (28900, 23)\n"
     ]
    }
   ],
   "source": [
    "files = ['train03_val_minus_0p5','train04_val_minus_0p5','train10_val_minus_0p5','train18_val_minus_0p5',\n",
    "         'train21_val_minus_0p5','train14_val_minus_0p5','train19_val_minus_0p5','train24_val_minus_0p5']\n",
    "FIRST_TIME=True\n",
    "for i in range(len(files)):\n",
    "    conv_val_feat = load_array('/cat/home/ubuntu/cat/out/features/train/'+files[i]+'_sqznt.dat')\n",
    "    labels_val = load_array('/cat/home/ubuntu/cat/in/train/labels/'+files[i]+'_labels.dat')\n",
    "    if FIRST_TIME:\n",
    "        predictions_all = lrg_model.predict(conv_val_feat) \n",
    "        predictions_all = np.hstack((predictions_all[0],predictions_all[1][:,0:4],predictions_all[2][:,0:2]))\n",
    "        labels_all = labels_val\n",
    "        FIRST_TIME = False\n",
    "    else:\n",
    "        temp = lrg_model.predict(conv_val_feat)\n",
    "        temp = np.hstack((temp[0],temp[1][:,0:4],temp[2][:,0:2]))\n",
    "        predictions_all = np.vstack((predictions_all,temp))\n",
    "        labels_all = np.vstack((labels_all,labels_val))\n",
    "    del(conv_val_feat,labels_val)\n",
    "    gc.collect()\n",
    "print predictions_all.shape, labels_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_all = labels_all[:,2:23]\n",
    "labels_all[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]] = labels_all[:,[0,5,6,9,10,11,12,13,14,15,16,17,18,19,20,1,2,3,4,7,8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write code to do Test Time Augmentation by taking 10 non-random patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.497888835052\n",
      "1 0.949548121687\n",
      "2 0.995430544234\n",
      "3 0.485128756854\n",
      "4 0.999702267613\n",
      "5 0.955531330181\n",
      "6 0.984763388126\n",
      "7 0.996314836684\n",
      "8 0.937283389651\n",
      "9 0.943551282563\n",
      "10 0.971013999751\n",
      "11 0.926554614044\n",
      "12 0.603605573328\n",
      "13 0.499896067902\n",
      "14 0.723801280942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/metrics/ranking.py:538: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 nan\n",
      "16 0.904718184235\n",
      "17 0.923579599281\n",
      "18 0.891071262348\n",
      "19 0.919400295589\n",
      "20 0.972723613317\n",
      "0.854075362169\n"
     ]
    }
   ],
   "source": [
    "# Computing the area under the ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from math import isnan\n",
    "\n",
    "totalScore=0\n",
    "count = 0\n",
    "\n",
    "predictions_temp = np.copy(predictions_all)\n",
    "truth_temp = np.copy(labels_all)\n",
    "\n",
    "for j in range(21):   \n",
    "    index = 0\n",
    "    #remove rows with label = 0.5\n",
    "    for i in range(labels_all.shape[0]):\n",
    "        if labels_all[i,j] != 0.5:\n",
    "            truth_temp[index,j]=labels_all[i,j]\n",
    "            predictions_temp[index,j]=predictions_all[i,j]\n",
    "            index += 1\n",
    "    fpr, tpr, _ = roc_curve(truth_temp[0:index,j], predictions_temp[0:index,j])\n",
    "    score = auc(fpr, tpr)\n",
    "    print j, score\n",
    "    if isnan(score):\n",
    "        score=0.0\n",
    "    else:\n",
    "        totalScore+=score\n",
    "        count +=1\n",
    "    \n",
    "print totalScore/count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  train21 ; 0.957 \n",
    "\n",
    "  train22 ; 0.972\n",
    "\n",
    "  train23 ; 0.993\n",
    "\n",
    "  train24 ; 0.924\n",
    "\n",
    "  train25 ; 0.865\n",
    "\n",
    "train21-5 ; 0.899\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del(conv_val_feat)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_hires = load_array('/cataract/home/ubuntu/cataract/03_output/train21_rgb_hires.dat')\n",
    "rgb_hires.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = load_array('/cataract/home/ubuntu/cataract/03_output/train21_labels.dat')\n",
    "labels[500,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_trn_feat = load_array('/cataract4/home/ubuntu/cataract4/03_output/train21_fcf_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels.shape,conv_trn_feat.shape,rgb_hires.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load weights\n",
    "l = lrg_model.layers\n",
    "conv_fn = K.function([l[0].input, K.learning_phase()], l[-4].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame=500\n",
    "inp = np.expand_dims(conv_trn_feat[frame], 0)\n",
    "conv = conv_fn([inp,0])[0,:,:,0]\n",
    "#conv = conv_fn([inp,0])\n",
    "conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cm2(inp, label):\n",
    "    conv = conv_fn([inp,0])[0,:,:,label]\n",
    "    return scipy.misc.imresize(conv, (360,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotImages(frame):\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    colors = ['red', 'brown', 'yellow', 'green', 'blue']\n",
    "    cmap = LinearSegmentedColormap.from_list('name', colors)\n",
    "    norm = plt.Normalize(0, 254)\n",
    "    inp = np.expand_dims(conv_trn_feat[frame], 0)\n",
    "    index_array = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "    f = plt.figure(figsize=(10, 40))\n",
    "    r = len(index_array)\n",
    "\n",
    "    A = np.transpose(rgb_hires,(0,2,3,1))[frame,]\n",
    "\n",
    "    for k, i in enumerate(index_array):\n",
    "        for j , M in enumerate([A,A,A]):\n",
    "            sp = f.add_subplot(r, 3, 3*k + j + 1)\n",
    "            sp.axis('Off')\n",
    "            if j==0:\n",
    "                plt.imshow(M)\n",
    "            else:\n",
    "                if j==1:\n",
    "                    plt.imshow(get_cm2(inp, i), cmap='cool', norm=norm, interpolation='none') \n",
    "                else:\n",
    "                    plt.imshow(M)\n",
    "                    plt.imshow(get_cm2(inp, i), cmap='cool', norm=norm, interpolation='none', alpha=0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "256 convolutions filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotImages(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotImages(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plotImages(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plotImages(3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plotImages(1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels[600,2:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plotImages(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "128 convolution filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotImages(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.transpose(rgb_hires,(0,2,3,1))[1000,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = get_cm2(inp, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(cm, cmap=\"hot\") # binary cross entropy with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(np.transpose(rgb_hires,(0,2,3,1))[1000,])\n",
    "plt.imshow(cm, cmap=\"hot\", alpha=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = get_cm2(inp, 7)\n",
    "plt.imshow(cm, cmap=\"gray\") # binary cross entropy with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = [0.01,0.001,0.0001,0.00001]\n",
    "e =[1,2,2,2]\n",
    "p = [0.6]\n",
    "tuneMyNw('fold_4','03_output/features',lr,e,p,get_lrg_layers,batch_size,allTags=True,base_model=None,early_stop=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels = loadFeatures('03_output/features','fold_4')\n",
    "predictFolds('fold_4',get_bn_layers,'vgg',features,allTags=True,base_model='vgg')\n",
    "np.savetxt('03_output/results/labels_vgg_fold_4.csv', labels, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tags = ['all']\n",
    "\n",
    "learningSchedules = {}\n",
    "learningSchedules['1'] = [0.01,0.001,0.0001]\n",
    "learningSchedules['2'] = [0.01,0.001]\n",
    "learningSchedules['3'] = [0.01]\n",
    "\n",
    "epochSchedules = {}\n",
    "epochSchedules['1'] = [1,2,4]\n",
    "epochSchedules['2'] = [1,2]\n",
    "epochSchedules['3'] = [1,2,3]\n",
    "epochSchedules['4'] = [1,2,5]\n",
    "epochSchedules['5'] = [1]\n",
    "epochSchedules['6'] = [1,2,1]\n",
    "\n",
    "dropouts = [0.8]\n",
    "learningSchedule = ['1']\n",
    "epochSchedule = ['1']\n",
    "\n",
    "features, labels = loadFeatures('03_output/features','train')\n",
    "trainFolds('test',tags,dropouts,learningSchedule,learningSchedules,epochSchedule,epochSchedules,\n",
    "           get_bn_layers,'vgg',features, labels,batch_size,allTags=True,base_model='vgg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels = loadFeatures('03_output/testfeatures', 'test')\n",
    "predictFolds('test',get_bn_layers,'vgg',features,allTags=True,base_model='vgg')\n",
    "np.savetxt('03_output/results/labels_vgg_test.csv', labels, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io,transform\n",
    "%matplotlib inline\n",
    "\n",
    "def data_aug(img = img):\n",
    "\tmu = 0\n",
    "\tsigma = 0.1\n",
    "\tfeature_vec=np.matrix(evecs_mat)\n",
    "\n",
    "\t# 3 x 1 scaled eigenvalue matrix\n",
    "\tse = np.zeros((3,1))\n",
    "\tse[0][0] = np.random.normal(mu, sigma)*evals[0]\n",
    "\tse[1][0] = np.random.normal(mu, sigma)*evals[1]\n",
    "\tse[2][0] = np.random.normal(mu, sigma)*evals[2]\n",
    "\tse = np.matrix(se)\n",
    "\tval = feature_vec*se\n",
    "\n",
    "\t# Parse through every pixel value.\n",
    "\tfor i in xrange(img.shape[0]):\n",
    "\t\tfor j in xrange(img.shape[1]):\n",
    "\t\t\t# Parse through every dimension.\n",
    "\t\t\tfor k in xrange(img.shape[2]):\n",
    "\t\t\t\timg[i,j,k] = float(img[i,j,k]) + float(val[k])\n",
    "\n",
    "imnames = ['n00.jpg','n01.jpg','n02.jpg','n03.jpg','n04.jpg','n05.jpg']\n",
    "#load list of images\n",
    "imlist = (io.imread_collection(imnames))\n",
    "\n",
    "res = np.zeros(shape=(1,3))\n",
    "for i in range(len(imlist)):\n",
    "\t# re-size all images to 256 x 256 x 3\n",
    "\tm=transform.resize(imlist[i],(256,256,3))\n",
    "\t# re-shape to make list of RGB vectors.\n",
    "\tarr=m.reshape((256*256),3)\n",
    "\t# consolidate RGB vectors of all images\n",
    "\tres = np.concatenate((res,arr),axis=0)\n",
    "res = np.delete(res, (0), axis=0)\n",
    "\n",
    "# subtracting the mean from each dimension\n",
    "m = res.mean(axis = 0)\n",
    "res = res - m\n",
    "\n",
    "R = np.cov(res, rowvar=False)\n",
    "print R\n",
    "\n",
    "from numpy import linalg as LA\n",
    "evals, evecs = LA.eigh(R)\n",
    "\n",
    "idx = np.argsort(evals)[::-1]\n",
    "evecs = evecs[:,idx]\n",
    "# sort eigenvectors according to same index\n",
    "\n",
    "evals = evals[idx]\n",
    "# select the first 3 eigenvectors (3 is desired dimension\n",
    "# of rescaled data array)\n",
    "\n",
    "evecs = evecs[:, :3]\n",
    "# carry out the transformation on the data using eigenvectors\n",
    "# and return the re-scaled data, eigenvalues, and eigenvectors\n",
    "m = np.dot(evecs.T, res.T).T\n",
    "\n",
    "# perturbing color in image[0]\n",
    "# re-scaling from 0-1\n",
    "img = imlist[0]/255.0\n",
    "data_aug(img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelFile = load_array('/cataract/home/ubuntu/cataract/03_output/train01_labels.dat')\n",
    "features = load_array('/cataract2/home/ubuntu/cataract2/03_output/train01_fcf_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model.fit(conv_trn_feat, labels[:,2:23], batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(conv_val_feat, labels_val[:,2:23])) #binary cross entropy with sigmoid n = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auc_tool(truth_directory, prediction_directory, tool):\n",
    "    \"\"\"Computes the area under the ROC curve for one tool.\n",
    "    \"\"\"\n",
    "    filename = ''\n",
    "    try:\n",
    "    truth = []\n",
    "    predictions = []\n",
    "    # loop on (truth, predictions) file pairs\n",
    "    for file in range(1, num_files + 1):\n",
    "\n",
    "    # getting the filenames\n",
    "    if (file < 10):\n",
    "    filename = file_prefix + '0{}.csv'.format(file)\n",
    "    else:\n",
    "    filename = file_prefix + '{}.csv'.format(file)\n",
    "    truth_filename = join(truth_directory, filename)\n",
    "    prediction_filename = join(prediction_directory, filename)\n",
    "    # parsing the right column for the current tool\n",
    "    truth_data = read_csv(truth_filename, header = 0, skipinitialspace = True,\n",
    "    usecols = [tool], squeeze = True, dtype = 'float32').tolist()\n",
    "    prediction_data = read_csv(prediction_filename, header = None, skipinitialspace = True,\n",
    "    usecols = [tool], squeeze = True, dtype = 'float32').tolist()\n",
    "    if len(truth_data) != len(prediction_data):\n",
    "    raise ValueError('Files {} and {} have different row counts'.\n",
    "    format(truth_filename, prediction_filename))\n",
    "\n",
    "    # appending rows with consensual ground truth\n",
    "    indices = [index for index, value in enumerate(truth_data) if value != 0.5]\n",
    "    truth += [truth_data[index] for index in indices]\n",
    "    predictions += [prediction_data[index] for index in indices]\n",
    "\n",
    "    # computing the area under the ROC curve\n",
    "    fpr, tpr, _ = roc_curve(truth, predictions)\n",
    "    score = auc(fpr, tpr)\n",
    "    return 0. if isnan(score) else score\n",
    "    except Exception as e:\n",
    "    print('Error: missing column in {} for tool number {}!'.format(filename, tool)\n",
    "    if 'Usecols' in str(e) else 'Error: {}!'.format(e))\n",
    "    return 0.\n",
    "\n",
    "\n",
    "    def main():\n",
    "    \"\"\"Main function.\n",
    "    \"\"\"\n",
    "\n",
    "    # parsing the command line\n",
    "    parser = ArgumentParser(description = 'Evaluator for the CATARACTS challenge.')\n",
    "    parser.add_argument('-t', '--truth', required = True, help = 'directory containing ground truth files')\n",
    "    parser.add_argument('-p', '--predictions', required = True, help = 'directory containing automatic predictions')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # computing tool-specific scores\n",
    "    scores = []\n",
    "    for tool in range(1, num_tools + 1):\n",
    "    score = auc_tool(args.truth, args.predictions, tool)\n",
    "    print('Score tool {0}: {1:.4f}'.format(tool, score))\n",
    "    scores.append(score)\n",
    "\n",
    "    # computing the average score\n",
    "    print('Average: {0:.4f}'.format(sum(scores) / float(len(scores))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path='../03_output/'\n",
    "name='train01'\n",
    "rgb_hires = load_array(path + name + '_rgb_hires.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_hires.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_feat = vgg640.predict(rgb_hires[1:100], batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_hires = load_array('03_output/train01_rgb_hires.dat')\n",
    "labels = load_array('03_output/train01_labels.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_hires_val = load_array('03_output/train25_rgb_hires.dat')\n",
    "labels_val = load_array('03_output/train25_labels.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_hires_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_hires = np.reshape(np.transpose(rgb_hires,(1,0)),(2460,360,640,3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_hires_val = np.reshape(np.transpose(rgb_hires_val,(1,0)),(6990,360,640,3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_hires.shape, labels.shape,rgb_hires_val.shape, labels_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rgb_hires = np.transpose(rgb_hires,(0,3,1,2)) \n",
    "rgb_hires_val = np.transpose(rgb_hires_val,(0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = np.transpose(labels,(1,0))\n",
    "labels_val = np.transpose(labels_val,(1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_hires.shape\n",
    "plt.imshow(rgb_hires[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_trn_feat = vgg640.predict(rgb_hires_val, batch_size=32, verbose=1)\n",
    "conv_val_feat = vgg640.predict(rgb_hires, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_array('03_output/train25_fcn_feat.dat',conv_trn_feat)\n",
    "save_array('03_output/train01_fcn_feat.dat',conv_val_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layers,_ = split_at(vgg640, Convolution2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nf=128; p=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nf=256; p=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nf=256; p=0.2\n",
    "def get_lrg_layers():\n",
    "    return [\n",
    "        BatchNormalization(axis=1, input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(21,3,3, border_mode='same'),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Activation('softmax')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lrg_layers():\n",
    "    return [\n",
    "        BatchNormalization(axis=1, input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(21,3,3, border_mode='same'),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Activation('sigmoid')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model = Sequential(get_lrg_layers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrg_model.compile(Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model.fit(conv_trn_feat, labels_val[:,1:22], batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(conv_val_feat, labels[:,1:22])) #binary cross entropy with sigmoid n = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model.fit(conv_trn_feat, labels_val[:,1:22], batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(conv_val_feat, labels[:,1:22])) #binary cross entropy with softmax n = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model.fit(conv_trn_feat, labels_val[:,1:22], batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(conv_val_feat, labels[:,1:22])) #binary cross entropy with sigmoid n = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrg_model.optimizer.lr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model.fit(conv_trn_feat, labels_val[:,1:22], batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, labels[:,1:22])) #categorical cross entropy with softmax n = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model.fit(conv_trn_feat, labels_val[:,1:22], batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, labels[:,1:22])) #binary cross entropy with softmax n = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model.fit(conv_trn_feat, labels_val[:,1:22], batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, labels[:,1:22])) #binary cross entropy with sigmoid  n = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model.fit(conv_trn_feat, labels_val[:,1:22], batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, labels[:,1:22])) #binary cross entropy with softmax n = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = lrg_model.layers\n",
    "conv_fn = K.function([l[0].input, K.learning_phase()], l[-3].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cm2(inp, label):\n",
    "    conv = conv_fn([inp,0])[0, label]\n",
    "    return scipy.misc.imresize(conv, (360,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = np.expand_dims(conv_val_feat[400], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(to_plot(rgb_hires[400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = get_cm2(inp, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(cm, cmap=\"cool\") # binary cross entropy with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plot(rgb_hires[400])\n",
    "plt.imshow(cm, cmap=\"cool\", alpha=0.5) #plt.imshow(cm, cmap=\"cool\") # binary cross entropy with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(cm, cmap=\"cool\") # binary cross entropy with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plot(rgb_hires[400])\n",
    "plt.imshow(cm, cmap=\"cool\", alpha=0.5) #plt.imshow(cm, cmap=\"cool\") # binary cross entropy with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = get_cm2(inp, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(cm, cmap=\"gray\") # binary cross entropy with softmax n = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plot(rgb_hires[400])\n",
    "plt.imshow(cm, cmap=\"gray\", alpha=0.5) #plt.imshow(cm, cmap=\"cool\") # binary cross entropy with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels[400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = ['train02','train03','train04','train05','train06','train07','train08','train09','train10','train11',\n",
    "         'train12','train13','train14','train15','train16','train17','train18','train19','train20','train21','train22',\n",
    "         'train23','train24','train25'] \n",
    "\n",
    "labels = load_array('../03_output/train01_labels.dat')\n",
    "for i in tqdm(range(len(files))):\n",
    "    lbl = load_array('../03_output/'+files[i]+'_labels.dat')\n",
    "    labels = np.vstack((labels,lbl))\n",
    "    del(lbl)\n",
    "    gc.collect()\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anyLabel = sum(np.transpose(labels)[3:23,:])\n",
    "unique, counts = np.unique(anyLabel, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels[labels==0.5]=999\n",
    "anyLabel = sum(np.transpose(labels)[3:23,:])\n",
    "unique, counts = np.unique(anyLabel, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'0',36060/82479.0,'1',13838/82479.0,'2',30591/82479.0,'0.5 or 1.5 or 2.5 or 3', (1595+334+27+34)/82479.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anyLabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "lagggedLabels = shift(anyLabel, -15, cval=1)\n",
    "lagggedLabels[lagggedLabels<0.5]=0\n",
    "for i in range(30):\n",
    "    temp = shift(anyLabel, -14+i, cval=1)\n",
    "    temp[temp<0.5]=0\n",
    "    lagggedLabels = np.vstack((lagggedLabels,temp))\n",
    "\n",
    "lagggedLabels.shape\n",
    "anyLabelLag15 = sum(lagggedLabels)\n",
    "anyLabelLag15.shape\n",
    "anyLabelLag15[anyLabelLag15>0]=1\n",
    "unique, counts = np.unique(anyLabelLag15, return_counts=True)\n",
    "unique, counts\n",
    "keepOrNot = np.vstack((anyLabel,anyLabelLag15)).T\n",
    "keepOrNot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(keepOrNot[:,0], return_counts=True)\n",
    "unique, counts"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
