{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create Feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Conv2D, MaxPooling2D, UpSampling2D, GlobalMaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from random import uniform\n",
    "import bcolz\n",
    "from time import *\n",
    "from keras.layers import merge\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers import Input, Dense\n",
    "import math\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils as u\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "import resnet50; reload(resnet50)\n",
    "from resnet50 import Resnet50\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import myFunctionsv3; reload(myFunctionsv3)\n",
    "from myFunctionsv3 import *\n",
    "from  keras.applications.resnet50 import ResNet50\n",
    "from squeezenet import SqueezeNet\n",
    "#from densenet import DenseNet, DenseNetImageNet121\n",
    "\n",
    "import gc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SqueezeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirement keras 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a base model using squeezenet and initialize with imagenet weights. Add a lambda layer at the beginning to normalize and remove the fully connected layers at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imagenet_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape(1,1,3)\n",
    "\n",
    "def squeezenet_preprocess(x):\n",
    "    \"\"\"\n",
    "        Subtracts the mean RGB value, and transposes RGB to BGR.\n",
    "        The mean RGB was computed on the image set used to train the RESNET model.\n",
    "\n",
    "        Args: \n",
    "            x: Image array (height x width x channels)\n",
    "        Returns:\n",
    "            Image array (height x width x transposed_channels)\n",
    "    \"\"\"\n",
    "    x = x - imagenet_mean\n",
    "    #x = x[...,[2,1,0]] # reverse axis rgb->bgr\n",
    "    x = x[..., ::-1]\n",
    "\n",
    "    return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(squeezenet_preprocess, input_shape=(360,640,3), output_shape=(360,640,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "squeezenet = SqueezeNet(input_shape=(360,640,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_11 (Lambda)           (None, 360, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 21, 39, 512)       722496    \n",
      "=================================================================\n",
      "Total params: 722,496.0\n",
      "Trainable params: 722,496.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Model(inputs=squeezenet.input, outputs=squeezenet.layers[-6].output))\n",
    "model.compile(SGD(0.05), 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precompute the features and save to disk to save training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createFeatures(path,name):\n",
    "    rgb_hires = load_array(path + name + '_hires.dat')\n",
    "    conv_feat = model.predict(rgb_hires, batch_size=64, verbose=0)\n",
    "    save_array('/home/ubuntu/features/'+name+'_sqznt.dat',conv_feat)\n",
    "    del(conv_feat,rgb_hires)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "files = ['trainfold0','trainfold1','trainfold3','trainfold4', 'trainfold5'] \n",
    "for i in tqdm(range(len(files))):\n",
    "    createFeatures('/cat/home/ubuntu/cat/in/train/folds/',files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = ['train03_val_minus_0p5','train04_val_minus_0p5','train10_val_minus_0p5','train18_val_minus_0p5',\n",
    "         'train21_val_minus_0p5','train14_val_minus_0p5','train19A_val_minus_0p5','train19B_val_minus_0p5','train24_val_minus_0p5',\n",
    "        'train03top_left_val_minus_0p5','train04top_left_val_minus_0p5','train10top_left_val_minus_0p5','train18top_left_val_minus_0p5',\n",
    "         'train21top_left_val_minus_0p5','train14top_left_val_minus_0p5','train19Atop_left_val_minus_0p5','train19Btop_left_val_minus_0p5','train24top_left_val_minus_0p5',\n",
    "        'train03top_right_val_minus_0p5','train04top_right_val_minus_0p5','train10top_right_val_minus_0p5','train18top_right_val_minus_0p5',\n",
    "         'train21top_right_val_minus_0p5','train14top_right_val_minus_0p5','train19Atop_right_val_minus_0p5','train19Btop_right_val_minus_0p5','train24top_right_val_minus_0p5',\n",
    "        'train03bottom_left_val_minus_0p5','train04bottom_left_val_minus_0p5','train10bottom_left_val_minus_0p5','train18bottom_left_val_minus_0p5',\n",
    "         'train21bottom_left_val_minus_0p5','train14bottom_left_val_minus_0p5','train19Abottom_left_val_minus_0p5','train19Bbottom_left_val_minus_0p5','train24bottom_left_val_minus_0p5',\n",
    "        'train03bottom_right_val_minus_0p5','train04bottom_right_val_minus_0p5','train10bottom_right_val_minus_0p5','train18bottom_right_val_minus_0p5',\n",
    "         'train21bottom_right_val_minus_0p5','train14bottom_right_val_minus_0p5','train19Abottom_right_val_minus_0p5','train19Bbottom_right_val_minus_0p5','train24bottom_right_val_minus_0p5'\n",
    "        ]\n",
    "\n",
    "for i in tqdm(range(len(files))):\n",
    "    createFeatures('/cat/home/ubuntu/cat/in/train/hires/',files[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirement keras 2.0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dense = DenseNetImageNet121(input_shape=(360,640,3),weights='imagenet',include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model(inputs = dense.input, outputs = dense.layers[-18].output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDenseNetFeatures(path,name):\n",
    "    rgb_hires = load_array(path + name + '_hires.dat')\n",
    "    conv_feat = model.predict(rgb_hires, batch_size=32, verbose=0)\n",
    "    save_array('/cat/home/ubuntu/cat/out/features/train/'+name+'_dnsnt.dat',conv_feat)\n",
    "    del(conv_feat,rgb_hires)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = ['trainfold1','trainfold2','trainfold3','trainfold4','trainfold5',\n",
    "         'trainfold6','trainfold7','trainfold8','trainfold9','trainfold0'] \n",
    "\n",
    "for i in tqdm(range(len(files))):\n",
    "    createDenseNetFeatures('/cat/home/ubuntu/cat/in/train/folds/',files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = ['train03_val_minus_0p5','train04_val_minus_0p5','train10_val_minus_0p5','train18_val_minus_0p5',\n",
    "         'train21_val_minus_0p5','train14_val_minus_0p5','train19_val_minus_0p5','train24_val_minus_0p5']\n",
    "for i in tqdm(range(len(files))):\n",
    "    createDenseNetFeatures('/cat/home/ubuntu/cat/in/train/hires/',files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
