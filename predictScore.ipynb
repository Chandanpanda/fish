{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SQUEEZENET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available  (error: Unable to get the number of gpus available: unknown error)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Conv2D, MaxPooling2D, UpSampling2D, GlobalMaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from random import uniform\n",
    "import bcolz\n",
    "from time import *\n",
    "from keras.layers import merge\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers import Input, Dense\n",
    "import math\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils as u\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "import resnet50; reload(resnet50)\n",
    "from resnet50 import Resnet50\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import myFunctionsv3; reload(myFunctionsv3)\n",
    "from myFunctionsv3 import *\n",
    "from  keras.applications.resnet50 import ResNet50\n",
    "#from squeezenet import SqueezeNet\n",
    "\n",
    "import gc\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nf=128; p=0.01\n",
    "def get_lrg_layers():\n",
    "    \n",
    "    #inp = Input((21, 39, 512))\n",
    "    inp = Input((31, 56, 512))\n",
    "    x = BatchNormalization(axis=1)(inp)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(nf,(1,1), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(nf,(1,1), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(nf,(1,1), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    \n",
    "    x_15 = Conv2D(15,(3,3), activation='relu', padding='same')(x)\n",
    "    x_15 = BatchNormalization(axis=1)(x_15)\n",
    "    x_15 = GlobalMaxPooling2D()(x_15)\n",
    "    x_sig_15 = Activation('sigmoid')(x_15)\n",
    "    \n",
    "    x_4 = Conv2D(4,(3,3), activation='relu', padding='same')(x)\n",
    "    x_4 = BatchNormalization(axis=1)(x_4)\n",
    "    x_4 = GlobalMaxPooling2D()(x_4)\n",
    "    x_sof_4 = Activation('sigmoid')(x_4)\n",
    "    \n",
    "    x_2 = Conv2D(2,(3,3), activation='relu', padding='same')(x)\n",
    "    x_2 = BatchNormalization(axis=1)(x_2)\n",
    "    x_2 = GlobalMaxPooling2D()(x_2)\n",
    "    x_sof_2 = Activation('sigmoid')(x_2)\n",
    "    \n",
    "    model = Model([inp], [x_sig_15, x_sof_4, x_sof_2])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model = get_lrg_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 31, 56, 512)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 31, 56, 512)   124                                          \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 15, 28, 512)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 15, 28, 128)   65664                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 15, 28, 128)   60                                           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 15, 28, 128)   147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 15, 28, 128)   60                                           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 15, 28, 128)   147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 15, 28, 128)   60                                           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 7, 14, 128)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 7, 14, 128)    16512                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 7, 14, 128)    28                                           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 7, 14, 128)    147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 7, 14, 128)    28                                           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 7, 14, 128)    147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 7, 14, 128)    28                                           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 3, 7, 128)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 3, 7, 128)     16512                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 3, 7, 128)     12                                           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 3, 7, 128)     147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 3, 7, 128)     12                                           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 3, 7, 15)      17295                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 3, 7, 4)       4612                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 3, 7, 2)       2306                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 3, 7, 15)      12                                           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, 3, 7, 4)       12                                           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, 3, 7, 2)       12                                           \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalMa (None, 15)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling2d_2 (GlobalMa (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling2d_3 (GlobalMa (None, 2)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 15)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 2)             0                                            \n",
      "====================================================================================================\n",
      "Total params: 861,269.0\n",
      "Trainable params: 861,045.0\n",
      "Non-trainable params: 224.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lrg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24724"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nf=128; p=0.01\n",
    "def get_lrg_layers_2():\n",
    "    \n",
    "    inp = Input((31, 56, 512))\n",
    "    x = BatchNormalization(axis=1)(inp)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(nf,(1,1), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(nf,(1,1), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(nf,(1,1), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    \n",
    "    x_9 = Conv2D(9,(3,3), activation='relu', padding='same')(x)\n",
    "    x_9 = BatchNormalization(axis=1)(x_9)\n",
    "    x_9 = GlobalMaxPooling2D()(x_9)\n",
    "    x_sig_9 = Activation('sigmoid')(x_9)\n",
    "    \n",
    "    x_6 = Conv2D(6,(3,3), activation='relu', padding='same')(x)\n",
    "    x_6 = BatchNormalization(axis=1)(x_6)\n",
    "    x_6 = GlobalMaxPooling2D()(x_6)\n",
    "    x_sig_6 = Activation('sigmoid')(x_6)\n",
    "    \n",
    "    x_4 = Conv2D(5,(3,3), activation='relu', padding='same')(x)\n",
    "    x_4 = BatchNormalization(axis=1)(x_4)\n",
    "    x_4 = GlobalMaxPooling2D()(x_4)\n",
    "    x_sof_4 = Activation('softmax')(x_4)\n",
    "    \n",
    "    x_2 = Conv2D(3,(3,3), activation='relu', padding='same')(x)\n",
    "    x_2 = BatchNormalization(axis=1)(x_2)\n",
    "    x_2 = GlobalMaxPooling2D()(x_2)\n",
    "    x_sof_2 = Activation('softmax')(x_2)\n",
    "    \n",
    "    model = Model([inp], [x_sig_9,x_sig_6, x_sof_4, x_sof_2])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model2 = get_lrg_layers_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 31, 56, 512)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 31, 56, 512)  124         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 15, 28, 512)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 15, 28, 128)  65664       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 15, 28, 128)  60          conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 15, 28, 128)  147584      batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 15, 28, 128)  60          conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 15, 28, 128)  147584      batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 15, 28, 128)  60          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 7, 14, 128)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 14, 128)   16512       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 14, 128)   28          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 14, 128)   147584      batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 14, 128)   28          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 14, 128)   147584      batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 14, 128)   28          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 3, 7, 128)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 3, 7, 128)    16512       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 3, 7, 128)    12          conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 3, 7, 128)    147584      batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 3, 7, 128)    12          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 3, 7, 9)      10377       batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 3, 7, 6)      6918        batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 3, 7, 5)      5765        batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 3, 7, 3)      3459        batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 3, 7, 9)      12          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 3, 7, 6)      12          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 3, 7, 5)      12          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 3, 7, 3)      12          conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_11 (Global (None, 9)            0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_12 (Global (None, 6)            0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_13 (Global (None, 5)            0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_14 (Global (None, 3)            0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 9)            0           global_max_pooling2d_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 6)            0           global_max_pooling2d_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 5)            0           global_max_pooling2d_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 3)            0           global_max_pooling2d_14[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 863,587\n",
      "Trainable params: 863,357\n",
      "Non-trainable params: 230\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lrg_model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model I7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model2.load_weights('/cat/home/ubuntu/cat/out/weights/sqznt_weights_folds_8_9_128_Iteration8.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6,10,11,12,13,14,15,16,17,0,5,9,18,19,20,1,2,3,4,7,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28900, 21) (28900, 23)\n"
     ]
    }
   ],
   "source": [
    "files = ['train03_val_minus_0p5','train04_val_minus_0p5','train10_val_minus_0p5','train18_val_minus_0p5',\n",
    "         'train21_val_minus_0p5','train14_val_minus_0p5','train19_val_minus_0p5','train24_val_minus_0p5']\n",
    "FIRST_TIME=True\n",
    "for i in range(len(files)):\n",
    "    conv_val_feat = load_array('/cat/home/ubuntu/cat/out/features/train/'+files[i]+'_sqznt.dat')\n",
    "    labels_val = load_array('/cat/home/ubuntu/cat/in/train/labels/'+files[i]+'_labels.dat')\n",
    "    if FIRST_TIME:\n",
    "        predictions_all = lrg_model2.predict(conv_val_feat) \n",
    "        predictions_all = np.hstack((predictions_all[0][:,0:9],predictions_all[1][:,0:6],predictions_all[2][:,0:4],predictions_all[3][:,0:2]))\n",
    "        labels_all = labels_val\n",
    "        FIRST_TIME = False\n",
    "    else:\n",
    "        temp = lrg_model2.predict(conv_val_feat)\n",
    "        temp = np.hstack((temp[0][:,0:9],temp[1][:,0:6],temp[2][:,0:4],temp[3][:,0:2]))\n",
    "        predictions_all = np.vstack((predictions_all,temp))\n",
    "        labels_all = np.vstack((labels_all,labels_val))\n",
    "    del(conv_val_feat,labels_val)\n",
    "    gc.collect()\n",
    "print predictions_all.shape, labels_all.shape\n",
    "predictions_center = np.copy(predictions_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28900, 21) (28900, 23)\n"
     ]
    }
   ],
   "source": [
    "label_files = ['train03_val_minus_0p5','train04_val_minus_0p5','train10_val_minus_0p5','train18_val_minus_0p5',\n",
    "         'train21_val_minus_0p5','train14_val_minus_0p5','train19_val_minus_0p5','train24_val_minus_0p5']\n",
    "\n",
    "files = ['train03top_left_val_minus_0p5','train04top_left_val_minus_0p5','train10top_left_val_minus_0p5','train18top_left_val_minus_0p5',\n",
    "         'train21top_left_val_minus_0p5','train14top_left_val_minus_0p5','train19top_left_val_minus_0p5','train24top_left_val_minus_0p5']\n",
    "FIRST_TIME=True\n",
    "for i in range(len(files)):\n",
    "    conv_val_feat = load_array('/cat/home/ubuntu/cat/out/features/train/'+files[i]+'_sqznt.dat')\n",
    "    labels_val = load_array('/cat/home/ubuntu/cat/in/train/labels/'+label_files[i]+'_labels.dat')\n",
    "    if FIRST_TIME:\n",
    "        predictions_all = lrg_model2.predict(conv_val_feat) \n",
    "        predictions_all = np.hstack((predictions_all[0][:,0:9],predictions_all[1][:,0:6],predictions_all[2][:,0:4],predictions_all[3][:,0:2]))\n",
    "        labels_all = labels_val\n",
    "        FIRST_TIME = False\n",
    "    else:\n",
    "        temp = lrg_model2.predict(conv_val_feat)\n",
    "        temp = np.hstack((temp[0][:,0:9],temp[1][:,0:6],temp[2][:,0:4],temp[3][:,0:2]))\n",
    "        predictions_all = np.vstack((predictions_all,temp))\n",
    "        labels_all = np.vstack((labels_all,labels_val))\n",
    "    del(conv_val_feat,labels_val)\n",
    "    gc.collect()\n",
    "print predictions_all.shape, labels_all.shape\n",
    "predictions_top_left = np.copy(predictions_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28900, 21) (28900, 23)\n"
     ]
    }
   ],
   "source": [
    "label_files = ['train03_val_minus_0p5','train04_val_minus_0p5','train10_val_minus_0p5','train18_val_minus_0p5',\n",
    "         'train21_val_minus_0p5','train14_val_minus_0p5','train19_val_minus_0p5','train24_val_minus_0p5']\n",
    "files = ['train03top_right_val_minus_0p5','train04top_right_val_minus_0p5','train10top_right_val_minus_0p5','train18top_right_val_minus_0p5',\n",
    "         'train21top_right_val_minus_0p5','train14top_right_val_minus_0p5','train19top_right_val_minus_0p5','train24top_right_val_minus_0p5']\n",
    "FIRST_TIME=True\n",
    "for i in range(len(files)):\n",
    "    conv_val_feat = load_array('/cat/home/ubuntu/cat/out/features/train/'+files[i]+'_sqznt.dat')\n",
    "    labels_val = load_array('/cat/home/ubuntu/cat/in/train/labels/'+label_files[i]+'_labels.dat')\n",
    "    if FIRST_TIME:\n",
    "        predictions_all = lrg_model2.predict(conv_val_feat) \n",
    "        predictions_all = np.hstack((predictions_all[0][:,0:9],predictions_all[1][:,0:6],predictions_all[2][:,0:4],predictions_all[3][:,0:2]))\n",
    "        labels_all = labels_val\n",
    "        FIRST_TIME = False\n",
    "    else:\n",
    "        temp = lrg_model2.predict(conv_val_feat)\n",
    "        temp = np.hstack((temp[0][:,0:9],temp[1][:,0:6],temp[2][:,0:4],temp[3][:,0:2]))\n",
    "        predictions_all = np.vstack((predictions_all,temp))\n",
    "        labels_all = np.vstack((labels_all,labels_val))\n",
    "    del(conv_val_feat,labels_val)\n",
    "    gc.collect()\n",
    "print predictions_all.shape, labels_all.shape\n",
    "predictions_top_right = np.copy(predictions_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28900, 21) (28900, 23)\n"
     ]
    }
   ],
   "source": [
    "label_files = ['train03_val_minus_0p5','train04_val_minus_0p5','train10_val_minus_0p5','train18_val_minus_0p5',\n",
    "         'train21_val_minus_0p5','train14_val_minus_0p5','train19_val_minus_0p5','train24_val_minus_0p5']\n",
    "files = ['train03bottom_right_val_minus_0p5','train04bottom_right_val_minus_0p5','train10bottom_right_val_minus_0p5','train18bottom_right_val_minus_0p5',\n",
    "         'train21bottom_right_val_minus_0p5','train14bottom_right_val_minus_0p5','train19bottom_right_val_minus_0p5','train24bottom_right_val_minus_0p5']\n",
    "FIRST_TIME=True\n",
    "for i in range(len(files)):\n",
    "    conv_val_feat = load_array('/cat/home/ubuntu/cat/out/features/train/'+files[i]+'_sqznt.dat')\n",
    "    labels_val = load_array('/cat/home/ubuntu/cat/in/train/labels/'+label_files[i]+'_labels.dat')\n",
    "    if FIRST_TIME:\n",
    "        predictions_all = lrg_model2.predict(conv_val_feat) \n",
    "        predictions_all = np.hstack((predictions_all[0][:,0:9],predictions_all[1][:,0:6],predictions_all[2][:,0:4],predictions_all[3][:,0:2]))\n",
    "        labels_all = labels_val\n",
    "        FIRST_TIME = False\n",
    "    else:\n",
    "        temp = lrg_model2.predict(conv_val_feat)\n",
    "        temp = np.hstack((temp[0][:,0:9],temp[1][:,0:6],temp[2][:,0:4],temp[3][:,0:2]))\n",
    "        predictions_all = np.vstack((predictions_all,temp))\n",
    "        labels_all = np.vstack((labels_all,labels_val))\n",
    "    del(conv_val_feat,labels_val)\n",
    "    gc.collect()\n",
    "print predictions_all.shape, labels_all.shape\n",
    "predictions_bottom_right = np.copy(predictions_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28900, 21) (28900, 23)\n"
     ]
    }
   ],
   "source": [
    "label_files = ['train03_val_minus_0p5','train04_val_minus_0p5','train10_val_minus_0p5','train18_val_minus_0p5',\n",
    "         'train21_val_minus_0p5','train14_val_minus_0p5','train19_val_minus_0p5','train24_val_minus_0p5']\n",
    "files = ['train03bottom_left_val_minus_0p5','train04bottom_left_val_minus_0p5','train10bottom_left_val_minus_0p5','train18bottom_left_val_minus_0p5',\n",
    "         'train21bottom_left_val_minus_0p5','train14bottom_left_val_minus_0p5','train19bottom_left_val_minus_0p5','train24bottom_left_val_minus_0p5']\n",
    "FIRST_TIME=True\n",
    "for i in range(len(files)):\n",
    "    conv_val_feat = load_array('/cat/home/ubuntu/cat/out/features/train/'+files[i]+'_sqznt.dat')\n",
    "    labels_val = load_array('/cat/home/ubuntu/cat/in/train/labels/'+label_files[i]+'_labels.dat')\n",
    "    if FIRST_TIME:\n",
    "        predictions_all = lrg_model2.predict(conv_val_feat) \n",
    "        predictions_all = np.hstack((predictions_all[0][:,0:9],predictions_all[1][:,0:6],predictions_all[2][:,0:4],predictions_all[3][:,0:2]))\n",
    "        labels_all = labels_val\n",
    "        FIRST_TIME = False\n",
    "    else:\n",
    "        temp = lrg_model2.predict(conv_val_feat)\n",
    "        temp = np.hstack((temp[0][:,0:9],temp[1][:,0:6],temp[2][:,0:4],temp[3][:,0:2]))\n",
    "        predictions_all = np.vstack((predictions_all,temp))\n",
    "        labels_all = np.vstack((labels_all,labels_val))\n",
    "    del(conv_val_feat,labels_val)\n",
    "    gc.collect()\n",
    "print predictions_all.shape, labels_all.shape\n",
    "predictions_bottom_left = np.copy(predictions_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6,10,11,12,13,14,15,16,17,0,5,9,18,19,20,1,2,3,4,7,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_all = labels_all[:,2:23]\n",
    "labels_all[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]] = labels_all[:,[6,10,11,12,13,14,15,16,17,0,5,9,18,19,20,1,2,3,4,7,8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 21, 28900)\n"
     ]
    }
   ],
   "source": [
    "predictionals_all_patches = np.zeros([5, 21,predictions_center.shape[0]],dtype=np.float32)\n",
    "for i in range(21):\n",
    "    predictionals_all_patches[0,i] = predictions_center[:,i]\n",
    "    predictionals_all_patches[1,i] = predictions_top_left[:,i]\n",
    "    predictionals_all_patches[2,i] = predictions_top_right[:,i]\n",
    "    predictionals_all_patches[3,i] = predictions_bottom_right[:,i]\n",
    "    predictionals_all_patches[4,i] = predictions_bottom_left[:,i]\n",
    "print predictionals_all_patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictionals_all_patches_average2 = np.zeros([1, 21,predictions_center.shape[0]],dtype=np.float32)\n",
    "for i in range(21):\n",
    "    predictionals_all_patches_average2[0,i] = (predictionals_all_patches[0,i] + predictionals_all_patches[1,i] + predictionals_all_patches[2,i] + predictionals_all_patches[3,i] + predictionals_all_patches[4,i])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictionals_all_patches_average2 = predictions_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictionals_all_patches_average2 = predictionals_all_patches_average2[0]\n",
    "predictionals_all_patches_average2 = np.transpose(predictionals_all_patches_average2,(1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5\n",
      "1 0.998922162599\n",
      "2 0.926481170686\n",
      "3 0.968421606379\n",
      "4 0.5\n",
      "5 0.5\n",
      "6 0.858570697198\n",
      "7 0.936598582618\n",
      "8 0.931129496064\n",
      "9 0.5\n",
      "10 0.260520227289\n",
      "11 0.63500805487\n",
      "12 0.602991919822\n",
      "13 1.0\n",
      "14 0.374429634759\n",
      "15 nan\n",
      "16 0.776779227354\n",
      "17 0.828757151304\n",
      "18 0.878686621061\n",
      "19 0.954246891119\n",
      "20 0.938328171593\n",
      "0.743493580736\n"
     ]
    }
   ],
   "source": [
    "# Computing the area under the ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from math import isnan\n",
    "\n",
    "totalScore=0\n",
    "count = 0\n",
    "\n",
    "predictions_temp = np.copy(predictionals_all_patches_average2)\n",
    "truth_temp = np.copy(labels_all)\n",
    "\n",
    "for j in range(21):   \n",
    "    index = 0\n",
    "    #remove rows with label = 0.5\n",
    "    for i in range(labels_all.shape[0]):\n",
    "        if labels_all[i,j] != 0.5:\n",
    "            truth_temp[index,j]=labels_all[i,j]\n",
    "            predictions_temp[index,j]=predictionals_all_patches_average2[i,j]\n",
    "            index += 1\n",
    "    fpr, tpr, _ = roc_curve(truth_temp[0:index,j], predictions_temp[0:index,j])\n",
    "    score = auc(fpr, tpr)\n",
    "    print j, score\n",
    "    if isnan(score):\n",
    "        score=0.0\n",
    "    else:\n",
    "        totalScore+=score\n",
    "        count +=1\n",
    "    \n",
    "print totalScore/count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Iteration 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrg_model.load_weights('/cat/home/ubuntu/cat/out/weights/sqznt_weights_folds_8_9_128_Iteration13L.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0,5,6,9,10,11,12,13,14,15,16,17,18,19,20,1,2,3,4,7,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31687, 21) (31687, 23)\n"
     ]
    }
   ],
   "source": [
    "files = ['train03_val_minus_0p5','train04_val_minus_0p5','train10_val_minus_0p5','train18_val_minus_0p5',\n",
    "         'train21_val_minus_0p5','train14_val_minus_0p5','train19A_val_minus_0p5','train19B_val_minus_0p5','train24_val_minus_0p5']\n",
    "FIRST_TIME=True\n",
    "for i in range(len(files)):\n",
    "    conv_val_feat = load_array('/cat4/home/ubuntu/cat4/out/features/train/'+files[i]+'_sqznt.dat')\n",
    "    labels_val = load_array('/cat/home/ubuntu/cat/in/train/labels/'+files[i]+'_labels.dat')\n",
    "    if FIRST_TIME:\n",
    "        predictions_all = lrg_model.predict(conv_val_feat) \n",
    "        predictions_all = np.hstack((predictions_all[0][:,0:15],predictions_all[1][:,0:4],predictions_all[2][:,0:2]))\n",
    "        labels_all = labels_val\n",
    "        FIRST_TIME = False\n",
    "    else:\n",
    "        temp = lrg_model.predict(conv_val_feat)\n",
    "        temp = np.hstack((temp[0][:,0:15],temp[1][:,0:4],temp[2][:,0:2]))\n",
    "        predictions_all = np.vstack((predictions_all,temp))\n",
    "        labels_all = np.vstack((labels_all,labels_val))\n",
    "    del(conv_val_feat,labels_val)\n",
    "    gc.collect()\n",
    "print predictions_all.shape, labels_all.shape\n",
    "predictions_center = np.copy(predictions_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31687, 21) (31687, 23)\n"
     ]
    }
   ],
   "source": [
    "label_files = ['train03_val_minus_0p5','train04_val_minus_0p5','train10_val_minus_0p5','train18_val_minus_0p5',\n",
    "         'train21_val_minus_0p5','train14_val_minus_0p5','train19A_val_minus_0p5','train19B_val_minus_0p5','train24_val_minus_0p5']\n",
    "\n",
    "files = ['train03top_left_val_minus_0p5','train04top_left_val_minus_0p5','train10top_left_val_minus_0p5','train18top_left_val_minus_0p5',\n",
    "         'train21top_left_val_minus_0p5','train14top_left_val_minus_0p5','train19Atop_left_val_minus_0p5','train19Btop_left_val_minus_0p5','train24top_left_val_minus_0p5']\n",
    "\n",
    "FIRST_TIME=True\n",
    "for i in range(len(files)):\n",
    "    conv_val_feat = load_array('/cat4/home/ubuntu/cat4/out/features/train/'+files[i]+'_sqznt.dat')\n",
    "    labels_val = load_array('/cat/home/ubuntu/cat/in/train/labels/'+label_files[i]+'_labels.dat')\n",
    "    if FIRST_TIME:\n",
    "        predictions_all = lrg_model.predict(conv_val_feat) \n",
    "        predictions_all = np.hstack((predictions_all[0][:,0:15],predictions_all[1][:,0:4],predictions_all[2][:,0:2]))\n",
    "        labels_all = labels_val\n",
    "        FIRST_TIME = False\n",
    "    else:\n",
    "        temp = lrg_model.predict(conv_val_feat)\n",
    "        temp = np.hstack((temp[0][:,0:15],temp[1][:,0:4],temp[2][:,0:2]))\n",
    "        predictions_all = np.vstack((predictions_all,temp))\n",
    "        labels_all = np.vstack((labels_all,labels_val))\n",
    "    del(conv_val_feat,labels_val)\n",
    "    gc.collect()\n",
    "print predictions_all.shape, labels_all.shape\n",
    "predictions_top_left = np.copy(predictions_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31687, 21) (31687, 23)\n"
     ]
    }
   ],
   "source": [
    "label_files = ['train03_val_minus_0p5','train04_val_minus_0p5','train10_val_minus_0p5','train18_val_minus_0p5',\n",
    "         'train21_val_minus_0p5','train14_val_minus_0p5','train19A_val_minus_0p5','train19B_val_minus_0p5','train24_val_minus_0p5']\n",
    "\n",
    "files = ['train03top_right_val_minus_0p5','train04top_right_val_minus_0p5','train10top_right_val_minus_0p5','train18top_right_val_minus_0p5',\n",
    "         'train21top_right_val_minus_0p5','train14top_right_val_minus_0p5','train19Atop_right_val_minus_0p5','train19Btop_right_val_minus_0p5','train24top_right_val_minus_0p5']\n",
    "\n",
    "FIRST_TIME=True\n",
    "for i in range(len(files)):\n",
    "    conv_val_feat = load_array('/cat4/home/ubuntu/cat4/out/features/train/'+files[i]+'_sqznt.dat')\n",
    "    labels_val = load_array('/cat/home/ubuntu/cat/in/train/labels/'+label_files[i]+'_labels.dat')\n",
    "    if FIRST_TIME:\n",
    "        predictions_all = lrg_model.predict(conv_val_feat) \n",
    "        predictions_all = np.hstack((predictions_all[0][:,0:15],predictions_all[1][:,0:4],predictions_all[2][:,0:2]))\n",
    "        labels_all = labels_val\n",
    "        FIRST_TIME = False\n",
    "    else:\n",
    "        temp = lrg_model.predict(conv_val_feat)\n",
    "        temp = np.hstack((temp[0][:,0:15],temp[1][:,0:4],temp[2][:,0:2]))\n",
    "        predictions_all = np.vstack((predictions_all,temp))\n",
    "        labels_all = np.vstack((labels_all,labels_val))\n",
    "    del(conv_val_feat,labels_val)\n",
    "    gc.collect()\n",
    "print predictions_all.shape, labels_all.shape\n",
    "predictions_top_right = np.copy(predictions_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31687, 21) (31687, 23)\n"
     ]
    }
   ],
   "source": [
    "label_files = ['train03_val_minus_0p5','train04_val_minus_0p5','train10_val_minus_0p5','train18_val_minus_0p5',\n",
    "         'train21_val_minus_0p5','train14_val_minus_0p5','train19A_val_minus_0p5','train19B_val_minus_0p5','train24_val_minus_0p5']\n",
    "\n",
    "files = ['train03bottom_right_val_minus_0p5','train04bottom_right_val_minus_0p5','train10bottom_right_val_minus_0p5','train18bottom_right_val_minus_0p5',\n",
    "         'train21bottom_right_val_minus_0p5','train14bottom_right_val_minus_0p5','train19Abottom_right_val_minus_0p5','train19Bbottom_right_val_minus_0p5','train24bottom_right_val_minus_0p5']\n",
    "\n",
    "FIRST_TIME=True\n",
    "for i in range(len(files)):\n",
    "    conv_val_feat = load_array('/cat4/home/ubuntu/cat4/out/features/train/'+files[i]+'_sqznt.dat')\n",
    "    labels_val = load_array('/cat/home/ubuntu/cat/in/train/labels/'+label_files[i]+'_labels.dat')\n",
    "    if FIRST_TIME:\n",
    "        predictions_all = lrg_model.predict(conv_val_feat) \n",
    "        predictions_all = np.hstack((predictions_all[0][:,0:15],predictions_all[1][:,0:4],predictions_all[2][:,0:2]))\n",
    "        labels_all = labels_val\n",
    "        FIRST_TIME = False\n",
    "    else:\n",
    "        temp = lrg_model.predict(conv_val_feat)\n",
    "        temp = np.hstack((temp[0][:,0:15],temp[1][:,0:4],temp[2][:,0:2]))\n",
    "        predictions_all = np.vstack((predictions_all,temp))\n",
    "        labels_all = np.vstack((labels_all,labels_val))\n",
    "    del(conv_val_feat,labels_val)\n",
    "    gc.collect()\n",
    "print predictions_all.shape, labels_all.shape\n",
    "predictions_bottom_right = np.copy(predictions_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31687, 21) (31687, 23)\n"
     ]
    }
   ],
   "source": [
    "label_files = ['train03_val_minus_0p5','train04_val_minus_0p5','train10_val_minus_0p5','train18_val_minus_0p5',\n",
    "         'train21_val_minus_0p5','train14_val_minus_0p5','train19A_val_minus_0p5','train19B_val_minus_0p5','train24_val_minus_0p5']\n",
    "\n",
    "files = ['train03bottom_left_val_minus_0p5','train04bottom_left_val_minus_0p5','train10bottom_left_val_minus_0p5','train18bottom_left_val_minus_0p5',\n",
    "         'train21bottom_left_val_minus_0p5','train14bottom_left_val_minus_0p5','train19Abottom_left_val_minus_0p5','train19Bbottom_left_val_minus_0p5','train24bottom_left_val_minus_0p5']\n",
    "\n",
    "FIRST_TIME=True\n",
    "for i in range(len(files)):\n",
    "    conv_val_feat = load_array('/cat4/home/ubuntu/cat4/out/features/train/'+files[i]+'_sqznt.dat')\n",
    "    labels_val = load_array('/cat/home/ubuntu/cat/in/train/labels/'+label_files[i]+'_labels.dat')\n",
    "    if FIRST_TIME:\n",
    "        predictions_all = lrg_model.predict(conv_val_feat) \n",
    "        predictions_all = np.hstack((predictions_all[0][:,0:15],predictions_all[1][:,0:4],predictions_all[2][:,0:2]))\n",
    "        labels_all = labels_val\n",
    "        FIRST_TIME = False\n",
    "    else:\n",
    "        temp = lrg_model.predict(conv_val_feat)\n",
    "        temp = np.hstack((temp[0][:,0:15],temp[1][:,0:4],temp[2][:,0:2]))\n",
    "        predictions_all = np.vstack((predictions_all,temp))\n",
    "        labels_all = np.vstack((labels_all,labels_val))\n",
    "    del(conv_val_feat,labels_val)\n",
    "    gc.collect()\n",
    "print predictions_all.shape, labels_all.shape\n",
    "predictions_bottom_left = np.copy(predictions_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_all = labels_all[:,2:23]\n",
    "labels_all[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]] = labels_all[:,[0,5,6,9,10,11,12,13,14,15,16,17,18,19,20,1,2,3,4,7,8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 21, 31687)\n"
     ]
    }
   ],
   "source": [
    "predictionals_all_patches = np.zeros([5, 21,predictions_center.shape[0]],dtype=np.float32)\n",
    "for i in range(21):\n",
    "    predictionals_all_patches[0,i] = predictions_center[:,i]\n",
    "    predictionals_all_patches[1,i] = predictions_top_left[:,i]\n",
    "    predictionals_all_patches[2,i] = predictions_top_right[:,i]\n",
    "    predictionals_all_patches[3,i] = predictions_bottom_right[:,i]\n",
    "    predictionals_all_patches[4,i] = predictions_bottom_left[:,i]\n",
    "print predictionals_all_patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictionals_all_patches_average = np.zeros([1, 21,predictions_center.shape[0]],dtype=np.float32)\n",
    "for i in range(21):\n",
    "    predictionals_all_patches_average[0,i] = (predictionals_all_patches[0,i] + predictionals_all_patches[1,i] + predictionals_all_patches[2,i] + predictionals_all_patches[3,i] + predictionals_all_patches[4,i])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictionals_all_patches_average = predictionals_all_patches_average[0]\n",
    "predictionals_all_patches_average = np.transpose(predictionals_all_patches_average,(1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.496764622329\n",
      "1 0.498478123018\n",
      "2 0.997314026187\n",
      "3 0.496432258914\n",
      "4 0.999932642923\n",
      "5 0.981278148222\n",
      "6 0.967036042556\n",
      "7 0.996522992279\n",
      "8 0.987424017717\n",
      "9 0.989334631048\n",
      "10 0.997448591013\n",
      "11 0.961565693138\n",
      "12 0.910348332306\n",
      "13 0.497203968154\n",
      "14 0.756524164351\n",
      "15 0.499899369381\n",
      "16 0.500692136097\n",
      "17 0.951198285249\n",
      "18 0.946398710624\n",
      "19 0.979275359802\n",
      "20 0.960762959981\n",
      "0.82723024168\n"
     ]
    }
   ],
   "source": [
    "# Computing the area under the ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from math import isnan\n",
    "\n",
    "totalScore=0\n",
    "count = 0\n",
    "\n",
    "predictions_temp = np.copy(predictionals_all_patches_average)\n",
    "truth_temp = np.copy(labels_all)\n",
    "\n",
    "for j in range(21):   \n",
    "    index = 0\n",
    "    #remove rows with label = 0.5\n",
    "    for i in range(labels_all.shape[0]):\n",
    "        if labels_all[i,j] != 0.5:\n",
    "            truth_temp[index,j]=labels_all[i,j]\n",
    "            predictions_temp[index,j]=predictionals_all_patches_average[i,j]\n",
    "            index += 1\n",
    "    fpr, tpr, _ = roc_curve(truth_temp[0:index,j], predictions_temp[0:index,j])\n",
    "    score = auc(fpr, tpr)\n",
    "    print j, score\n",
    "    if isnan(score):\n",
    "        score=0.0\n",
    "    else:\n",
    "        totalScore+=score\n",
    "        count +=1\n",
    "    \n",
    "print totalScore/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_hires = load_array('/cataract/home/ubuntu/cataract/03_output/train21_rgb_hires.dat')\n",
    "rgb_hires.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = load_array('/cataract/home/ubuntu/cataract/03_output/train21_labels.dat')\n",
    "labels[500,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_trn_feat = load_array('/cataract4/home/ubuntu/cataract4/03_output/train21_fcf_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels.shape,conv_trn_feat.shape,rgb_hires.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load weights\n",
    "l = lrg_model.layers\n",
    "conv_fn = K.function([l[0].input, K.learning_phase()], l[-4].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame=500\n",
    "inp = np.expand_dims(conv_trn_feat[frame], 0)\n",
    "conv = conv_fn([inp,0])[0,:,:,0]\n",
    "#conv = conv_fn([inp,0])\n",
    "conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cm2(inp, label):\n",
    "    conv = conv_fn([inp,0])[0,:,:,label]\n",
    "    return scipy.misc.imresize(conv, (360,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotImages(frame):\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    colors = ['red', 'brown', 'yellow', 'green', 'blue']\n",
    "    cmap = LinearSegmentedColormap.from_list('name', colors)\n",
    "    norm = plt.Normalize(0, 254)\n",
    "    inp = np.expand_dims(conv_trn_feat[frame], 0)\n",
    "    index_array = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "    f = plt.figure(figsize=(10, 40))\n",
    "    r = len(index_array)\n",
    "\n",
    "    A = np.transpose(rgb_hires,(0,2,3,1))[frame,]\n",
    "\n",
    "    for k, i in enumerate(index_array):\n",
    "        for j , M in enumerate([A,A,A]):\n",
    "            sp = f.add_subplot(r, 3, 3*k + j + 1)\n",
    "            sp.axis('Off')\n",
    "            if j==0:\n",
    "                plt.imshow(M)\n",
    "            else:\n",
    "                if j==1:\n",
    "                    plt.imshow(get_cm2(inp, i), cmap='cool', norm=norm, interpolation='none') \n",
    "                else:\n",
    "                    plt.imshow(M)\n",
    "                    plt.imshow(get_cm2(inp, i), cmap='cool', norm=norm, interpolation='none', alpha=0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "256 convolutions filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotImages(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotImages(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plotImages(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plotImages(3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plotImages(1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels[600,2:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plotImages(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "128 convolution filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotImages(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.transpose(rgb_hires,(0,2,3,1))[1000,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = get_cm2(inp, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(cm, cmap=\"hot\") # binary cross entropy with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(np.transpose(rgb_hires,(0,2,3,1))[1000,])\n",
    "plt.imshow(cm, cmap=\"hot\", alpha=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = get_cm2(inp, 7)\n",
    "plt.imshow(cm, cmap=\"gray\") # binary cross entropy with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = [0.01,0.001,0.0001,0.00001]\n",
    "e =[1,2,2,2]\n",
    "p = [0.6]\n",
    "tuneMyNw('fold_4','03_output/features',lr,e,p,get_lrg_layers,batch_size,allTags=True,base_model=None,early_stop=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels = loadFeatures('03_output/features','fold_4')\n",
    "predictFolds('fold_4',get_bn_layers,'vgg',features,allTags=True,base_model='vgg')\n",
    "np.savetxt('03_output/results/labels_vgg_fold_4.csv', labels, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tags = ['all']\n",
    "\n",
    "learningSchedules = {}\n",
    "learningSchedules['1'] = [0.01,0.001,0.0001]\n",
    "learningSchedules['2'] = [0.01,0.001]\n",
    "learningSchedules['3'] = [0.01]\n",
    "\n",
    "epochSchedules = {}\n",
    "epochSchedules['1'] = [1,2,4]\n",
    "epochSchedules['2'] = [1,2]\n",
    "epochSchedules['3'] = [1,2,3]\n",
    "epochSchedules['4'] = [1,2,5]\n",
    "epochSchedules['5'] = [1]\n",
    "epochSchedules['6'] = [1,2,1]\n",
    "\n",
    "dropouts = [0.8]\n",
    "learningSchedule = ['1']\n",
    "epochSchedule = ['1']\n",
    "\n",
    "features, labels = loadFeatures('03_output/features','train')\n",
    "trainFolds('test',tags,dropouts,learningSchedule,learningSchedules,epochSchedule,epochSchedules,\n",
    "           get_bn_layers,'vgg',features, labels,batch_size,allTags=True,base_model='vgg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels = loadFeatures('03_output/testfeatures', 'test')\n",
    "predictFolds('test',get_bn_layers,'vgg',features,allTags=True,base_model='vgg')\n",
    "np.savetxt('03_output/results/labels_vgg_test.csv', labels, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io,transform\n",
    "%matplotlib inline\n",
    "\n",
    "def data_aug(img = img):\n",
    "\tmu = 0\n",
    "\tsigma = 0.1\n",
    "\tfeature_vec=np.matrix(evecs_mat)\n",
    "\n",
    "\t# 3 x 1 scaled eigenvalue matrix\n",
    "\tse = np.zeros((3,1))\n",
    "\tse[0][0] = np.random.normal(mu, sigma)*evals[0]\n",
    "\tse[1][0] = np.random.normal(mu, sigma)*evals[1]\n",
    "\tse[2][0] = np.random.normal(mu, sigma)*evals[2]\n",
    "\tse = np.matrix(se)\n",
    "\tval = feature_vec*se\n",
    "\n",
    "\t# Parse through every pixel value.\n",
    "\tfor i in xrange(img.shape[0]):\n",
    "\t\tfor j in xrange(img.shape[1]):\n",
    "\t\t\t# Parse through every dimension.\n",
    "\t\t\tfor k in xrange(img.shape[2]):\n",
    "\t\t\t\timg[i,j,k] = float(img[i,j,k]) + float(val[k])\n",
    "\n",
    "imnames = ['n00.jpg','n01.jpg','n02.jpg','n03.jpg','n04.jpg','n05.jpg']\n",
    "#load list of images\n",
    "imlist = (io.imread_collection(imnames))\n",
    "\n",
    "res = np.zeros(shape=(1,3))\n",
    "for i in range(len(imlist)):\n",
    "\t# re-size all images to 256 x 256 x 3\n",
    "\tm=transform.resize(imlist[i],(256,256,3))\n",
    "\t# re-shape to make list of RGB vectors.\n",
    "\tarr=m.reshape((256*256),3)\n",
    "\t# consolidate RGB vectors of all images\n",
    "\tres = np.concatenate((res,arr),axis=0)\n",
    "res = np.delete(res, (0), axis=0)\n",
    "\n",
    "# subtracting the mean from each dimension\n",
    "m = res.mean(axis = 0)\n",
    "res = res - m\n",
    "\n",
    "R = np.cov(res, rowvar=False)\n",
    "print R\n",
    "\n",
    "from numpy import linalg as LA\n",
    "evals, evecs = LA.eigh(R)\n",
    "\n",
    "idx = np.argsort(evals)[::-1]\n",
    "evecs = evecs[:,idx]\n",
    "# sort eigenvectors according to same index\n",
    "\n",
    "evals = evals[idx]\n",
    "# select the first 3 eigenvectors (3 is desired dimension\n",
    "# of rescaled data array)\n",
    "\n",
    "evecs = evecs[:, :3]\n",
    "# carry out the transformation on the data using eigenvectors\n",
    "# and return the re-scaled data, eigenvalues, and eigenvectors\n",
    "m = np.dot(evecs.T, res.T).T\n",
    "\n",
    "# perturbing color in image[0]\n",
    "# re-scaling from 0-1\n",
    "img = imlist[0]/255.0\n",
    "data_aug(img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelFile = load_array('/cataract/home/ubuntu/cataract/03_output/train01_labels.dat')\n",
    "features = load_array('/cataract2/home/ubuntu/cataract2/03_output/train01_fcf_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model.fit(conv_trn_feat, labels[:,2:23], batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(conv_val_feat, labels_val[:,2:23])) #binary cross entropy with sigmoid n = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auc_tool(truth_directory, prediction_directory, tool):\n",
    "    \"\"\"Computes the area under the ROC curve for one tool.\n",
    "    \"\"\"\n",
    "    filename = ''\n",
    "    try:\n",
    "    truth = []\n",
    "    predictions = []\n",
    "    # loop on (truth, predictions) file pairs\n",
    "    for file in range(1, num_files + 1):\n",
    "\n",
    "    # getting the filenames\n",
    "    if (file < 10):\n",
    "    filename = file_prefix + '0{}.csv'.format(file)\n",
    "    else:\n",
    "    filename = file_prefix + '{}.csv'.format(file)\n",
    "    truth_filename = join(truth_directory, filename)\n",
    "    prediction_filename = join(prediction_directory, filename)\n",
    "    # parsing the right column for the current tool\n",
    "    truth_data = read_csv(truth_filename, header = 0, skipinitialspace = True,\n",
    "    usecols = [tool], squeeze = True, dtype = 'float32').tolist()\n",
    "    prediction_data = read_csv(prediction_filename, header = None, skipinitialspace = True,\n",
    "    usecols = [tool], squeeze = True, dtype = 'float32').tolist()\n",
    "    if len(truth_data) != len(prediction_data):\n",
    "    raise ValueError('Files {} and {} have different row counts'.\n",
    "    format(truth_filename, prediction_filename))\n",
    "\n",
    "    # appending rows with consensual ground truth\n",
    "    indices = [index for index, value in enumerate(truth_data) if value != 0.5]\n",
    "    truth += [truth_data[index] for index in indices]\n",
    "    predictions += [prediction_data[index] for index in indices]\n",
    "\n",
    "    # computing the area under the ROC curve\n",
    "    fpr, tpr, _ = roc_curve(truth, predictions)\n",
    "    score = auc(fpr, tpr)\n",
    "    return 0. if isnan(score) else score\n",
    "    except Exception as e:\n",
    "    print('Error: missing column in {} for tool number {}!'.format(filename, tool)\n",
    "    if 'Usecols' in str(e) else 'Error: {}!'.format(e))\n",
    "    return 0.\n",
    "\n",
    "\n",
    "    def main():\n",
    "    \"\"\"Main function.\n",
    "    \"\"\"\n",
    "\n",
    "    # parsing the command line\n",
    "    parser = ArgumentParser(description = 'Evaluator for the CATARACTS challenge.')\n",
    "    parser.add_argument('-t', '--truth', required = True, help = 'directory containing ground truth files')\n",
    "    parser.add_argument('-p', '--predictions', required = True, help = 'directory containing automatic predictions')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # computing tool-specific scores\n",
    "    scores = []\n",
    "    for tool in range(1, num_tools + 1):\n",
    "    score = auc_tool(args.truth, args.predictions, tool)\n",
    "    print('Score tool {0}: {1:.4f}'.format(tool, score))\n",
    "    scores.append(score)\n",
    "\n",
    "    # computing the average score\n",
    "    print('Average: {0:.4f}'.format(sum(scores) / float(len(scores))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path='../03_output/'\n",
    "name='train01'\n",
    "rgb_hires = load_array(path + name + '_rgb_hires.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_hires.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_feat = vgg640.predict(rgb_hires[1:100], batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_hires = load_array('03_output/train01_rgb_hires.dat')\n",
    "labels = load_array('03_output/train01_labels.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_hires_val = load_array('03_output/train25_rgb_hires.dat')\n",
    "labels_val = load_array('03_output/train25_labels.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_hires_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_hires = np.reshape(np.transpose(rgb_hires,(1,0)),(2460,360,640,3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_hires_val = np.reshape(np.transpose(rgb_hires_val,(1,0)),(6990,360,640,3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_hires.shape, labels.shape,rgb_hires_val.shape, labels_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rgb_hires = np.transpose(rgb_hires,(0,3,1,2)) \n",
    "rgb_hires_val = np.transpose(rgb_hires_val,(0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = np.transpose(labels,(1,0))\n",
    "labels_val = np.transpose(labels_val,(1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_hires.shape\n",
    "plt.imshow(rgb_hires[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_trn_feat = vgg640.predict(rgb_hires_val, batch_size=32, verbose=1)\n",
    "conv_val_feat = vgg640.predict(rgb_hires, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_array('03_output/train25_fcn_feat.dat',conv_trn_feat)\n",
    "save_array('03_output/train01_fcn_feat.dat',conv_val_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layers,_ = split_at(vgg640, Convolution2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nf=128; p=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nf=256; p=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nf=256; p=0.2\n",
    "def get_lrg_layers():\n",
    "    return [\n",
    "        BatchNormalization(axis=1, input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(21,3,3, border_mode='same'),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Activation('softmax')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lrg_layers():\n",
    "    return [\n",
    "        BatchNormalization(axis=1, input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(21,3,3, border_mode='same'),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Activation('sigmoid')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model = Sequential(get_lrg_layers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrg_model.compile(Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model.fit(conv_trn_feat, labels_val[:,1:22], batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(conv_val_feat, labels[:,1:22])) #binary cross entropy with sigmoid n = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model.fit(conv_trn_feat, labels_val[:,1:22], batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(conv_val_feat, labels[:,1:22])) #binary cross entropy with softmax n = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model.fit(conv_trn_feat, labels_val[:,1:22], batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(conv_val_feat, labels[:,1:22])) #binary cross entropy with sigmoid n = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrg_model.optimizer.lr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model.fit(conv_trn_feat, labels_val[:,1:22], batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, labels[:,1:22])) #categorical cross entropy with softmax n = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model.fit(conv_trn_feat, labels_val[:,1:22], batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, labels[:,1:22])) #binary cross entropy with softmax n = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model.fit(conv_trn_feat, labels_val[:,1:22], batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, labels[:,1:22])) #binary cross entropy with sigmoid  n = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrg_model.fit(conv_trn_feat, labels_val[:,1:22], batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, labels[:,1:22])) #binary cross entropy with softmax n = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = lrg_model.layers\n",
    "conv_fn = K.function([l[0].input, K.learning_phase()], l[-3].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cm2(inp, label):\n",
    "    conv = conv_fn([inp,0])[0, label]\n",
    "    return scipy.misc.imresize(conv, (360,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = np.expand_dims(conv_val_feat[400], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(to_plot(rgb_hires[400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = get_cm2(inp, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(cm, cmap=\"cool\") # binary cross entropy with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plot(rgb_hires[400])\n",
    "plt.imshow(cm, cmap=\"cool\", alpha=0.5) #plt.imshow(cm, cmap=\"cool\") # binary cross entropy with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(cm, cmap=\"cool\") # binary cross entropy with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plot(rgb_hires[400])\n",
    "plt.imshow(cm, cmap=\"cool\", alpha=0.5) #plt.imshow(cm, cmap=\"cool\") # binary cross entropy with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = get_cm2(inp, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(cm, cmap=\"gray\") # binary cross entropy with softmax n = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plot(rgb_hires[400])\n",
    "plt.imshow(cm, cmap=\"gray\", alpha=0.5) #plt.imshow(cm, cmap=\"cool\") # binary cross entropy with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels[400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = ['train02','train03','train04','train05','train06','train07','train08','train09','train10','train11',\n",
    "         'train12','train13','train14','train15','train16','train17','train18','train19','train20','train21','train22',\n",
    "         'train23','train24','train25'] \n",
    "\n",
    "labels = load_array('../03_output/train01_labels.dat')\n",
    "for i in tqdm(range(len(files))):\n",
    "    lbl = load_array('../03_output/'+files[i]+'_labels.dat')\n",
    "    labels = np.vstack((labels,lbl))\n",
    "    del(lbl)\n",
    "    gc.collect()\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anyLabel = sum(np.transpose(labels)[3:23,:])\n",
    "unique, counts = np.unique(anyLabel, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels[labels==0.5]=999\n",
    "anyLabel = sum(np.transpose(labels)[3:23,:])\n",
    "unique, counts = np.unique(anyLabel, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'0',36060/82479.0,'1',13838/82479.0,'2',30591/82479.0,'0.5 or 1.5 or 2.5 or 3', (1595+334+27+34)/82479.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anyLabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "lagggedLabels = shift(anyLabel, -15, cval=1)\n",
    "lagggedLabels[lagggedLabels<0.5]=0\n",
    "for i in range(30):\n",
    "    temp = shift(anyLabel, -14+i, cval=1)\n",
    "    temp[temp<0.5]=0\n",
    "    lagggedLabels = np.vstack((lagggedLabels,temp))\n",
    "\n",
    "lagggedLabels.shape\n",
    "anyLabelLag15 = sum(lagggedLabels)\n",
    "anyLabelLag15.shape\n",
    "anyLabelLag15[anyLabelLag15>0]=1\n",
    "unique, counts = np.unique(anyLabelLag15, return_counts=True)\n",
    "unique, counts\n",
    "keepOrNot = np.vstack((anyLabel,anyLabelLag15)).T\n",
    "keepOrNot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(keepOrNot[:,0], return_counts=True)\n",
    "unique, counts"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
