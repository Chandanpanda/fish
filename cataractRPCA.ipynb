{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Tool Annotation for Surgical Workflow Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Setup steps </b>\n",
    "\n",
    "pip install tqdm\n",
    "\n",
    "pip install imageio\n",
    "\n",
    "pip install moviepy\n",
    "\n",
    "pip install fbpca\n",
    "\n",
    "\n",
    "pip uninstall -y pillow\n",
    "\n",
    "CC=\"cc -mavx2\"\n",
    "pip install -U --force-reinstall pillow-simd\n",
    "\n",
    "\n",
    "<b> Outstanding Issues </b>\n",
    "\n",
    "1. RGB - to be solved. \n",
    "\n",
    "   1.a Do Robust PCA on R G and B channels separately and create final RBG M and S images - To be done\n",
    "   \n",
    "   1.b Try normalizing R G and B channels - To be done\n",
    "   \n",
    "   1.c Used Gray PCA to identify pixel mask to get Region of Interest from RGB - Done\n",
    "   \n",
    "   1.d Any other idea.. ??\n",
    "   \n",
    "\n",
    "\n",
    "2. resizing - solved\n",
    "\n",
    "\n",
    "3. memory - solved\n",
    "\n",
    "4. Tuning parameters\n",
    "\n",
    "    4.a Threshold - 3\n",
    "    \n",
    "    4.b k in video - 5 ps\n",
    "    \n",
    "    4.c k in pca - 4\n",
    "    \n",
    "    4.d maxiteration - 6\n",
    "    \n",
    "    4.e clip length  - 10s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to Do @ 9/3/2017\n",
    "\n",
    "1. Ensemble of PCA and FCN to generate masks\n",
    "2. UNET to build masks, bounding polygons\n",
    "3. Final Solution\n",
    "\n",
    "    3.a Multi output CNN to predict class and bounding box\n",
    "    \n",
    "    3.b UNET to predict bounding box by class\n",
    "    \n",
    "NEED TO REDO. BUG IN VIDEO ITERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "imageio.plugins.ffmpeg.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mpe\n",
    "from glob import glob\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import scipy\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "import fbpca\n",
    "import bcolz\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "import scipy.signal as sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MAX_ITERS = 10\n",
    "TOL=1e-9\n",
    "MAX_ITERS=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data_matrix_from_video(clip, k=5):\n",
    "    totalFrames = k * int(clip.duration)\n",
    "    FIRST_TIME = True\n",
    "    for i in range(totalFrames):\n",
    "        frame = resize(clip.get_frame(i/float(k)))\n",
    "        if(FIRST_TIME):\n",
    "            gray = rgb2gray(frame).flatten()\n",
    "            rgb = frame.flatten()\n",
    "            FIRST_TIME = False\n",
    "        else:\n",
    "            rgb = np.vstack((rgb,frame.flatten()))\n",
    "            gray = np.vstack((gray,rgb2gray(frame).flatten()))          \n",
    "    return gray.T,rgb.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def select_frames_from_data_matrix(mRGB,MASK,RGB,S, k=5, duration=30):\n",
    "    totalFrames = int(k * duration)\n",
    "    mRGBSize = mRGB.shape[1]\n",
    "    FIRST_TIME = True\n",
    "    for i in range(totalFrames):\n",
    "        frame = mRGB[:,i*mRGBSize/totalFrames]\n",
    "        maskSlice = MASK[:,i*mRGBSize/totalFrames]\n",
    "        rgbSlice = RGB[:,i*mRGBSize/totalFrames]\n",
    "        sSlice = S[:,i*mRGBSize/totalFrames]\n",
    "        if(FIRST_TIME):\n",
    "            mrgb = frame\n",
    "            mask = maskSlice\n",
    "            rgb = rgbSlice\n",
    "            s = sSlice\n",
    "            FIRST_TIME = False\n",
    "        else:\n",
    "            mrgb = np.vstack((mrgb,frame))\n",
    "            mask = np.vstack((mask,maskSlice))\n",
    "            rgb = np.vstack((rgb,rgbSlice))\n",
    "            s = np.vstack((s,sSlice))\n",
    "    return mrgb.T,mask.T,rgb.T,s.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize(frame):\n",
    "    w1 = frame.shape[0]\n",
    "    crop = (224-w1)/2\n",
    "    margin = (224-w1)/2\n",
    "    cons = np.int(np.median(frame))\n",
    "    img = frame.transpose(2,0,1).reshape(3,w1,224)\n",
    "    pads = ((margin,margin),(0,0))\n",
    "    img_arr = np.ndarray((3,224,224),np.int)\n",
    "    for i,x in enumerate(img):\n",
    "        x_p = np.pad(x,pads,'constant',constant_values=cons)\n",
    "        img_arr[i,:,:] = x_p\n",
    "    return np.uint8(img_arr).transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plt_images(M, A,index_array, dims, filename=None):\n",
    "    f = plt.figure(figsize=(10, 10))\n",
    "    r = len(index_array)\n",
    "    pics = r * 2\n",
    "    for k, i in enumerate(index_array):\n",
    "        for j, mat in enumerate([M, A]):\n",
    "            sp = f.add_subplot(r, 2, 2*k + j + 1)\n",
    "            sp.axis('Off')\n",
    "            pixels = mat[:,i]\n",
    "            if isinstance(pixels, scipy.sparse.csr_matrix):\n",
    "                pixels = pixels.todense()\n",
    "            plt.imshow(np.reshape(pixels, dims))\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plots(ims, dims, figsize=(15,20), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims)\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n",
    "        sp.axis('Off')\n",
    "        plt.imshow(np.reshape(ims[i], dims), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def converged(Z, d_norm):\n",
    "    err = np.linalg.norm(Z, 'fro') / d_norm\n",
    "    #print('error: ', err)\n",
    "    return err < TOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shrink(M, tau):\n",
    "    S = np.abs(M) - tau\n",
    "    return np.sign(M) * np.where(S>0, S, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _svd(M, rank): return fbpca.pca(M, k=min(rank, np.min(M.shape)), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_op(M): return _svd(M, 1)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svd_reconstruct(M, rank, min_sv):\n",
    "    u, s, v = _svd(M, rank)\n",
    "    s -= min_sv\n",
    "    nnz = (s > 0).sum()\n",
    "    return np.matmul(np.matmul(u[:,:nnz],np.diag(s[:nnz])) , v[:nnz]), nnz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pcp(X, maxiter=10, k=10): # refactored\n",
    "    m, n = X.shape\n",
    "    trans = m<n\n",
    "    if trans: X = X.T; m, n = X.shape\n",
    "        \n",
    "    lamda = 1/np.sqrt(m)\n",
    "    op_norm = norm_op(X)\n",
    "    Y = np.copy(X) / max(op_norm, np.linalg.norm( X, np.inf) / lamda)\n",
    "    mu = k*1.25/op_norm; mu_bar = mu * 1e7; rho = k * 1.5\n",
    "    \n",
    "    d_norm = np.linalg.norm(X, 'fro')\n",
    "    L = np.zeros_like(X); sv = 1\n",
    "    \n",
    "    examples = []\n",
    "    \n",
    "    for i in range(maxiter):\n",
    "        #print(\"rank sv:\", sv)\n",
    "        X2 = X + Y/mu\n",
    "        \n",
    "        # update estimate of Sparse Matrix by \"shrinking/truncating\": original - low-rank\n",
    "        S = shrink(X2 - L, lamda/mu)\n",
    "        \n",
    "        # update estimate of Low-rank Matrix by doing truncated SVD of rank sv & reconstructing.\n",
    "        # count of singular values > 1/mu is returned as svp\n",
    "        L, svp = svd_reconstruct(X2 - S, sv, 1/mu)\n",
    "        \n",
    "        # If svp < sv, you are already calculating enough singular values.\n",
    "        # If not, add 20% (in this case 240) to sv\n",
    "        sv = svp + (1 if svp < sv else round(0.05*n))\n",
    "        \n",
    "        # residual\n",
    "        Z = X - L - S\n",
    "        Y += mu*Z; mu *= rho\n",
    "        \n",
    "        examples.extend([S[140,:], L[140,:]])\n",
    "        \n",
    "        if m > mu_bar: m = mu_bar\n",
    "        if converged(Z, d_norm): break\n",
    "    \n",
    "    if trans: L=L.T; S=S.T\n",
    "    return L, S, examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maskRGB(RGB,S):\n",
    "    \n",
    "    totalFrames = RGB.shape[1]  \n",
    "    threshold = 3\n",
    "    FILL_VALUE = np.int(np.percentile(RGB,50))\n",
    "    cfilter = np.reshape(np.array([[0.111111111] * 9]),(3,3))\n",
    "    FIRST_TIME = True\n",
    "\n",
    "    for image in range(totalFrames):\n",
    "        S_conv = sci.convolve2d(np.reshape(S[:,image],(224,224)),cfilter,mode='same')\n",
    "        S_conv[abs(S_conv)<threshold]=0\n",
    "        S_conv[abs(S_conv)>=threshold]=1\n",
    "        mask = S_conv.astype(int)\n",
    "        rgbImage = np.reshape(RGB[:,image],(224,224,3))\n",
    "        img = rgbImage.transpose(2,0,1).reshape(3,224,224)\n",
    "        img_arr = np.ndarray((3,224,224),np.int)\n",
    "        for i,x in enumerate(img):\n",
    "            x_p = np.multiply(mask,x)\n",
    "            img_arr[i,:,:] = x_p\n",
    "        mask = (mask - 1)*-1\n",
    "\n",
    "        img_arr2 = np.ndarray((3,224,224),np.int)\n",
    "        for i,x in enumerate(img_arr):\n",
    "            x_p = x + mask*FILL_VALUE\n",
    "            img_arr2[i,:,:] = x_p\n",
    "        rgbImage = np.uint8(img_arr2).transpose(1,2,0)\n",
    "        if(FIRST_TIME):\n",
    "            mRGB = rgbImage.flatten()\n",
    "            MASK = mask.flatten()\n",
    "            FIRST_TIME = False\n",
    "        else:\n",
    "            mRGB = np.vstack((mRGB,rgbImage.flatten()))\n",
    "            MASK = np.vstack((MASK,mask.flatten()))\n",
    "    \n",
    "    return mRGB.T,MASK.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augmentData(path,name):\n",
    "    #Need to add  code to simultaneously augment all arrays together\n",
    "    #Need to add code to read and store labels\n",
    "    #Need to decide whether to overwrite arrays with augmented images or not\n",
    "    \n",
    "    mrgb = load_array(path+name+'_mRGB.dat')\n",
    "    hflip = ImageDataGenerator(horizontal_flip=True)\n",
    "    vflip = ImageDataGenerator(vertical_flip=True)\n",
    "    rotate = ImageDataGenerator(rotation_range=90)\n",
    "    zoom = ImageDataGenerator(zoom_range=(0.8,1.1))\n",
    "\n",
    "    totalFrames = mrgb.shape[1]\n",
    "    mrgbAug = np.zeros([totalFrames, 3, 224, 224 ],dtype=np.uint8)\n",
    "\n",
    "    for frameIndex in range(totalFrames):\n",
    "        x_train = np.reshape(mrgb[...,frameIndex],(224,224,3))\n",
    "        x_train = np.transpose(x_train,(2,0,1))\n",
    "        images_0 = np.zeros([1, 3, 224, 224 ],dtype=np.uint8)\n",
    "        labels_dummy = np.zeros([1, 1],dtype=np.int8)\n",
    "        images_0[0] = x_train\n",
    "        images = np.zeros([1, 3, 224, 224 ],dtype=np.uint8)\n",
    "        if frameIndex%5==0:\n",
    "            for x,y in hflip.flow(images_0,labels_dummy,batch_size=1):\n",
    "                mrgbAug[frameIndex] = x\n",
    "                break\n",
    "        if frameIndex%5==1:\n",
    "            for x,y in vflip.flow(images_0,labels_dummy,batch_size=1):\n",
    "                mrgbAug[frameIndex] = x\n",
    "                break\n",
    "        if frameIndex%5==2:\n",
    "            for x,y in rotate.flow(images_0,labels_dummy,batch_size=1):\n",
    "                mrgbAug[frameIndex] = x\n",
    "                break\n",
    "        if frameIndex%5==3:\n",
    "            for x,y in zoom.flow(images_0,labels_dummy,batch_size=1):\n",
    "                mrgbAug[frameIndex] = x\n",
    "                break\n",
    "        if frameIndex%5==4:\n",
    "            mrgbAug[frameIndex] = x_train\n",
    "    save_array(path+name+'_mRGBAug.dat',mrgbAug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processVideos(path,name):\n",
    "    l = 1920\n",
    "    w = 1080\n",
    "    w1 = int(224.0/l*w)\n",
    "    video = mpe.VideoFileClip(path+name+'.mp4',target_resolution=(w1,224))\n",
    "    clipDuration = 30\n",
    "    totalDuration = video.duration\n",
    "    countClips = int(math.ceil(totalDuration/clipDuration))\n",
    "    FIRST_TIME = True\n",
    "    chunkIndex = 0\n",
    "    for clipIndex in range(countClips):\n",
    "        clip = video.subclip(clipIndex*clipDuration,clipIndex*clipDuration+clipDuration)\n",
    "        M, RGB = create_data_matrix_from_video(clip, k = 29)\n",
    "        L, S, examples =  pcp(M, maxiter=6, k=4)\n",
    "        del(L,examples,M)\n",
    "        MRGB, MASK = maskRGB(RGB,S)\n",
    "        mRGBChunk,maskChunk,rgbChunk,sChunk = select_frames_from_data_matrix(MRGB,MASK,RGB,S)\n",
    "        del(MRGB,MASK,RGB,S)\n",
    "        gc.collect()\n",
    "        if(FIRST_TIME):\n",
    "            mRGB = mRGBChunk\n",
    "            mask = maskChunk\n",
    "            rgb = rgbChunk\n",
    "            s = sChunk\n",
    "            FIRST_TIME = False\n",
    "        else:\n",
    "            mRGB = np.hstack((mRGB,mRGBChunk))\n",
    "            mask = np.hstack((mask,maskChunk))\n",
    "            rgb = np.hstack((rgb,rgbChunk))\n",
    "            s = np.hstack((s,sChunk))  \n",
    "        del(mRGBChunk,maskChunk,rgbChunk,sChunk)\n",
    "        gc.collect()\n",
    "        if mRGB.shape[1]>2500:\n",
    "            save_array('../03_output/'+name+'_mRGB_%d.dat'%chunkIndex,mRGB)\n",
    "            save_array('../03_output/'+name+'_mask_%d.dat'%chunkIndex,mask)\n",
    "            save_array('../03_output/'+name+'_s_%d.dat'%chunkIndex,s)\n",
    "            save_array('../03_output/'+name+'_rgb_%d.dat'%chunkIndex,rgb)\n",
    "            chunkIndex = chunkIndex + 1\n",
    "            del(mRGB,mask,s,rgb)\n",
    "            gc.collect()\n",
    "            FIRST_TIME = True\n",
    "    save_array('../03_output/'+name+'_mRGB_%d.dat'%chunkIndex,mRGB)\n",
    "    save_array('../03_output/'+name+'_mask_%d.dat'%chunkIndex,mask)\n",
    "    save_array('../03_output/'+name+'_s_%d.dat'%chunkIndex,s)\n",
    "    save_array('../03_output/'+name+'_rgb_%d.dat'%chunkIndex,rgb)\n",
    "    del(mRGB,mask,s,rgb)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [3:12:08<4:59:38, 3595.65s/it]"
     ]
    }
   ],
   "source": [
    "videos = glob('../01_input/train/*.mp4')        \n",
    "for i in tqdm(range(len(videos))):\n",
    "    name = videos[i].split(\"../01_input/train/\")[1].split('.mp4')[0]\n",
    "    processVideos('../01_input/train/',name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "videos = glob('../01_input/test/*.mp4')        \n",
    "for i in tqdm(range(len(videos))):\n",
    "    name = videos[i].split(\"../01_input/test/\")[1].split('.mp4')[0]\n",
    "    processVideos('../01_input/test/',name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "videos = glob('../01_input/train/*.mp4')        \n",
    "for i in tqdm(range(len(videos))):\n",
    "    name = videos[i].split(\"../01_input/train/\")[1].split('.mp4')[0]\n",
    "    augmentData('../01_input/train/',name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "videos = glob('../01_input/test/*.mp4')        \n",
    "for i in tqdm(range(len(videos))):\n",
    "    name = videos[i].split(\"../01_input/test/\")[1].split('.mp4')[0]\n",
    "    augmentData('../01_input/train/',name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = pd.read_csv('../01_input/labels/train01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = 1920\n",
    "w = 1080\n",
    "w1 = int(224.0/l*w)\n",
    "path='../01_input/train/'\n",
    "name='train01'\n",
    "video = mpe.VideoFileClip(path+name+'.mp4',target_resolution=(w1,224))\n",
    "clipDuration = 10\n",
    "totalDuration = video.duration\n",
    "countClips = int(math.ceil(totalDuration/10))\n",
    "FIRST_TIME = True\n",
    "for clipIndex in range(countClips):\n",
    "    clip = video.subclip(clipIndex*clipDuration,clipIndex*clipDuration+clipDuration)\n",
    "    M, RGB = create_data_matrix_from_video(clip, k = 100)\n",
    "    L, S, examples =  pcp(M, maxiter=6, k=4)\n",
    "    del(L,examples,M)\n",
    "    MRGB, MASK = maskRGB(RGB,S)\n",
    "    mRGBChunk,maskChunk,rgbChunk,sChunk = select_frames_from_data_matrix(MRGB,MASK,RGB,S)\n",
    "    if(FIRST_TIME):\n",
    "        mRGB = mRGBChunk\n",
    "        mask = maskChunk\n",
    "        rgb = rgbChunk\n",
    "        s = sChunk\n",
    "        FIRST_TIME = False\n",
    "    else:\n",
    "        mRGB = np.hstack((mRGB,mRGBChunk))\n",
    "        mask = np.hstack((mask,maskChunk))\n",
    "        rgb = np.hstack((rgb,rgbChunk))\n",
    "        s = np.hstack((s,sChunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countClips = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for clipIndex in range(countClips):\n",
    "    clip = video.subclip(clipIndex*clipDuration,clipIndex*clipDuration+clipDuration)\n",
    "    M, RGB = create_data_matrix_from_video(clip, k = 100)\n",
    "    L, S, examples =  pcp(M, maxiter=6, k=4)\n",
    "    del(L,examples,M)\n",
    "    MRGB, MASK = maskRGB(RGB,S)\n",
    "    mRGBChunk,maskChunk,rgbChunk,sChunk = select_frames_from_data_matrix(MRGB,MASK,RGB,S)\n",
    "    if(FIRST_TIME):\n",
    "        mRGB = mRGBChunk\n",
    "        mask = maskChunk\n",
    "        rgb = rgbChunk\n",
    "        s = sChunk\n",
    "        FIRST_TIME = False\n",
    "    else:\n",
    "        mRGB = np.hstack((mRGB,mRGBChunk))\n",
    "        mask = np.hstack((mask,maskChunk))\n",
    "        rgb = np.hstack((rgb,rgbChunk))\n",
    "        s = np.hstack((s,sChunk))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mRGB.shape, mask.shape , rgb.shape , s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processVideos('../01_input/train/','train01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(mRGB[:,45],(224,224,3))) # k = 100 , 10 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mRGB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M.shape, S.shape, len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RGB = load_array('../03_output/train01_RGB.dat')\n",
    "S = load_array('../03_output/train01_S.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mRGB = maskRGB(RGB,S)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(mRGB[:,300],(224,224,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L, S, examples =  pcp(M, maxiter=6, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#debug\n",
    "videos = glob('../01_input/train/*.mp4')   \n",
    "totalDuration = 0\n",
    "for i in range(len(videos)):\n",
    "    name = videos[i].split(\"../01_input/train/\")[1].split('.mp4')[0]\n",
    "    video = mpe.VideoFileClip('../01_input/train/'+name+'.mp4')\n",
    "    print int(round(5*500/video.duration)), video.duration, video.size, video.fps, name\n",
    "    totalDuration += video.duration\n",
    "print totalDuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#debug\n",
    "#processVideos('../01_input/train/','train19')\n",
    "#M = np.load('../03_output/train19_M.npy')\n",
    "#S = np.load('../03_output/train19_S.npy')\n",
    "dims = (224,224,3)\n",
    "f = plt_images(M, S, [0, 50, 100], dims)\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
